---
title: "Bimodality Paper Draft"
author: "Kelly Heilman"
date: "March 7th, 2017"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Abstract: 

Climate changes have the potential to destabilize large biomes, driving rapid shifts in vegetation across large regions of the globe. Fear of future instability is driven by biomes with alternative states maintained by ecological feedback mechanisms, as theory indicates that at their thresholds can be tipped from one state to another by small changes in the environment. Although scientists observe non-linear responses to changes in climate across space, observations of threshold responses of alternative states to temporal shifts in environmental factors are lacking. We show that before Agro-industrial land conversion in the 1800’s, large regions of North America existed as bi-stable alternative states, but over ~150 years of land use change and fire suppression have stabilized (212,032 sq. km) the landscape. Projecting into the future, climate would destabilize alternative states in the region, but continued human impacts will maintain stability under changes in climate.

###Main Text:  

  	Anthropogenic climate changes are expected to alter the distribution of ecosystems and biomes across the globe. Response to these changes may be a continuous response to climate, or a non-linear threshold response in the case of unstable systems maintained by ecological feedback mechanisms. Biomes that can take alternative states within the same environmental space are considered particularly unstable to environmental changes. In these systems, ecological feedbacks maintain an ecosystem in one of the alternative states over a range of environmental space, but at a critical threshold, or ‘tipping point,’ small perturbations of the environment can result in non-linear transitions in vegetation. Thus, the sensitivity of alternative stable states at their "tipping points" represents a key uncertainty in understanding future responses to environmental changes. Observations of non-linear transitions of tree cover in space indicate that  savanna and forests are one such example of alternate stable states maintained by feedbacks between disturbance and canopy openness, driving widespread concern over the continued stability of the landscape (Staver et al. 2011, Hirota et al. 2011). However, most studies of alternative states are limited to very short timescales on the modern landscape, and as such, observations of a temporal response of these systems to rapid environmental changes are lacking and remain a key uncertainty in predictions for future vegetation distribution.
 Paragraph 2 text (can we split this up?, if so, should we put the modern data in the first paragraph). 
 
 	To explore the responses of alternative stable states to future environmental changes, we examine baseline historic and modern vegetation data from the North American savanna-forest boundary, a region affected by climate shifts, land use changes, and fire suppression since Agro-Industrial settlement.  We ask whether temperate savanna and forests were alternative stable states in the past, and will later compare the past to the modern vegetation to determine if these systems were resilient to large scale fire suppression, land use change, and shifts in climate over the last ~150 years in the region. The historical baseline vegetation data are tree density estimates from Public Land Surveys (PLS) across five states in the Upper Midwest (Supplemental figure of tree density). We focus on a metric of stand structure, tree density, in this analysis because vegetation structure feedbacks maintain savanna and forest alternative states elsewhere (Staver et al. 2011). Due to these feedbacks, a hallmark of alternative states is a bimodal or discontinuous distribution in tree cover/density that not explained by environmental discontinuities. Therefore, we focus on the distribution of tree density and its explanatory variables to identify savanna and forest alternative states. 
 	
  Before European Agricultural settlement in the Midwest, tree density was significantly bimodal across the entire Upper Midwest, with prominent modes at low tree density (30 trees/ha) and at high tree density (205 trees/ha) (Diptest p < 0.05, BC = 0.74306, Figure 1a). These modes are remarkably consistent with previous classifications of savanna (0.5 - 47 trees/ha) and forest (> 47 trees/ha), indicating that this bimodality separates low density savannas from high density closed forests (Goring et al. 2015, Anderson). To determine if the bimodality observed in tree density was due to discontinuous patterns in climate/edaphic factors, We evaluated tree density distributions over intervals of the scaled first principal component (PC1) of important environmental variables from the past: Mean Annual Precipitation, Mean annual temperature, Precipitation Seasonality Index, Temperature Coefficient of Variation, percent sand, and available water content of the soil (Supplemental Material). Tree density was significantly bimodal at PC1 intervals corresponding to intermediate precipitation and temperature levels (530 - 900 mm/year and 2 - 10 degC) (Figure 1b). Based on the climate space where tree density was bimodal, we estimate that up to 34% (212,032 km^2) of the past landscape had an environment where savanna and forests were alternative states that could potentially switch between two bistable states (Figure 1c).
  
  Over 150 years of environmental changes have influenced this region (cite), allowing us to explore the aggregate effect of climate, land use, and fire regime changes on the stability of the historically bi-stable vegetation in the region. Tree density distribution from the modern Forest Inventory Analysis (FIA) is not significantly bimodal between 0 and 500 trees/ha, showing a sharp stabilization of the landscape to closed forests (Figure 1d). This stabilization is largely driven by an increase in density in historically savanna dominated regions, while historically dense closed forests have decreased in tree density (Linear reg., R^2 = 0.4, p < 0.05, Figure 1e). Marked changes in climate over the last century is a potential factor underlying the observed shifts in ecosystem stability. However, based on the PLS era vegetation – climate relationship, observed climate shifts have slightly expanded the region where bi-stability occurs (Supplemental Figure). This predicted expansion would destabilize previously stable closed forests and result in bimodal closed forests that could be tipped into savannas (Supplemental figure). In sharp contrast to these predictions, modern vegetation data tell the story of overall stabilization of the modern landscape to pre-dominantly stable closed forests (Figure 1f), indicating that human impacts on the land, not climate have stabilized the landscape to modern forests.
  
	Conversion of alternative savanna and forest alternative states to predominantly  closed forest results in a change in ecosystem stability in the region and may have practical consequences for the future responses of vegetation to climate. Future predictions for the region typically use modern vegetation-climate relationships as baseline, but our analysis demonstrates a very different vegetation-climate relationship is possible for the region. To explore the implications of this, we predict regional stability under future climate using the past relationship between climate/soils and tree density. Using the past stability regime, climate changes projected under the RCP 2.6, RCP4.5, and RCP 8.5 emissions scenarios (for CMIP5 CCESM4 climate projections) would result in a 1-5% increase of regional instability, and drive shifts in the location of alternative stable states of Midwestern forests (Figure 4a).  This increase in instability under future climates would be particularly concerning. However, the current regime of fire suppression is likely to remain, and starting with a modern relationship between climate/soils and modern vegetation, the climate changes projected under the RCP 2.6, RCP4.5, and RCP 8.5 emissions scenarios (again for CCESM4 only) would likely result in stable closed forests in the Midwest, maintaining, or increasing ecosystem stability (Figure 4b). Thus, climate shifts alone would destabilize the region, but continued human impacts result in a future of continued stability.
	
	Previous studies focusing on savanna and forest alternative stable states document sharp transitions in tree cover with small changes in the environment, fueling fears of biome collapse under rapid environmental changes. We expand on this in this study by demonstrating actual shifts in stability with temporal environmental changes. Rather than the large scale collapse of forests, such as that feared in the tropics, this investigation documents a switch from bistable forests and savannas to stable closed forests over ~150 years of land use changes that are not fully attributable to climate shifts in the region. Therefore, at least for the temperate zone, human influence may have stabilized future responses to climatic shifts. However, as with the tropics, changes in disturbance regimes could return the region to historically bistable state, but it would require much clearing and land manager effort to maintain and convert stable forests to savanna ecosystems. 
	
  Whether the stability of the modern landscape will be maintained in the future may depend on maintenance of the current disturbance regimes (CITE recent land management paper). However, this does not preclude the possibility that drastic climate changes may drive large scale changes in tree mortality and tree density, particularly in predicted climates with no modern or past analogs (Figure 4). The no- analog climate space that is predicted to be much hotter and drier than historically observed in the region may pose a particular threat to stable closed forests composed of drought intolerant species (Frelich and Reich CITE). Additional uncertainty surrounding the distribution of future vegetation in the region may be driven by modern climate-vegetation relationships (CITE). Modern woody vegetation in the region is largely post-logging and/or post agricultural, resulting in a vegetation structure that is less correlated with climate and environmental covariates than it was in the past. The non-agricultural areas on the modern landscape have also experienced much longer fire return intervals than they did in the early 1900’s, but resulting in a modern era of fire suppression across the region (cite Abrams, USFS data). However, changes to disturbance regimes in the future, driven by climate shifts or human behavioral changes might result in altered future disturbance regimes. Since our predictions for a warmer future rely on current understanding of modern vegetation, this dependence on land-use, rather than local environmental factors may confound predictions of vegetation response to climate and large scale limits on tree growth.   Thus, including both our understanding of both the historic and modern vegetation-climate relationships, along with the non-linearity in the historic vegetation in predictive models may help improve future predictions.
  
  This analysis draws on responses of regional vegetation to long term changes in climate, land use, and fire regime to assess resilience of alternative stable states to environmental changes. While the PLS  corner points dataset provides a large scale regional snapshot of the pre-European settlement vegetation, forest plots surveyed from the FIA dataset are plot surveys that occur less frequently on the modern landscape (expand more on this). In this comparison between FIA and PLS datasets, we show that climate alone cannot explain shifts in transition, but we lack regional historical disturbance regime records needed to attribute vegetation shifts to fire suppression. Thus, we can conclude that land use changes, including both fire suppression and deforestation/logging likely played a large role in reshaping the Midwestern landscape. The influence of increased atmospheric CO2 may also aid development of stable closed forests in the region. Therefore, a further investigation into the role of atmospheric CO2 is needed before attributing the mechanism of stabilization in the region. 


  Here we take advantage of a large historical vegetation dataset to document alternative savanna and forest stable states in along a temperate ecotone. In addition to expanding the climatic range where savanna and forest alternative states are found, this analysis is the first to document the stabilization of alternative states to a single stable state in response to long term environmental changes that have altered the region over the last 150 years. While this analysis demonstrates regional shifts in stability with land use and fire regime changes, contrary to fears of forest collapse into low density savanna, vegetation shifted from alternative states to stable closed forest. This shift in stability will likely drive future stability, rather than large vegetation shifts in the face of climatic changes in the region, provided land use and fire suppression remain. 

  



## Figures:

### Figure 1: multipanel figure 
```{r, echo = FALSE}
densitys <- read.csv("data/midwest_pls_fia_density_alb1.6-5.csv")

# fia and pls plots
fig1A <- ggplot(densitys, aes(PLSdensity)) +geom_histogram(fill= "#D55E00",color = "black") +xlim(0, 700)+ xlab("PLS tree density (stems/ha)")+ ylab('# grid cells')+ 
        theme_bw(base_size = 10)
fig1D<- ggplot(densitys, aes(FIAdensity)) +geom_histogram(binwidth = 30,fill ="#0072B2",  color = 'black') +xlim(0, 700)+xlab('Modern Tree density (stems/ha)')+ylab("# grid cells")+
        theme_bw(base_size = 10)

dens <- densitys
dens$diff <- dens$FIAdensity - dens$PLSdensity

# density difference plots
fig1E <- ggplot(dens, aes(x = PLSdensity, y = diff))+ geom_point()+geom_density_2d() +geom_smooth(method = 'lm', color = 'red')+xlim(0,600)+
  theme_bw()+ ylab('increase in density \n since PLS (trees/ha)') + xlab('PLS tree density (trees/ha)') + annotate("text", x=400, y=900,label= paste("R-squared =", round(summary(lm(dens$PLSdensity ~ dens$diff))$adj.r.squared,2)), size = 5)






```



![](outputs/v1.6-5/FIA_PLS_hists.png)
![](outputs/v1.6-5/density_difference_plot.png)
![](outputs/v1.6-5/MAP_deltaTEMP_bimodal_space.png)
![](outputs/v1.6-5/MAP_TEMP_bimodal_space.png)
![](outputs/v1.6-5/full/PLS_PC1_PC2_map.png)
![](outputs/v1.6-5/FIA_PC1_PC2_map.png)

### Figure 2: 2 maps of rcp 8.5 
Using the climate space with reduced dimensionality (PC1) and the vegetation classificaitons from rheumtella, we can map out places where tree density was bimodal in the past:

![](outputs/v1.6-5/full/RCP_scenario_PC1_maps.png)

Also several places were no analog climates w.r.t. the PLS climate:
![](outputs/v1.6-5/full/RCP_scenario_PC1_noanalog_maps.png)

### Figure 4b: Stability maps for modern vegetation-environment relationship with CCSM4 future climate (2070-2099)
![](outputs/v1.6-5/RCP_scenario_PC1_maps_FIA.png)

Also several places were no analog climates w.r.t. the FIA climate:
![](outputs/v1.6-5/RCP_scenario_FIA_PC1_noanalog_maps.png)




Supplemental figures
![](outputs/v1.6-5/tree_density_maps_PLS_FIA.png)
![](outputs/v1.6-5/PLS__full_tree_density_map.png)



  
Supplemental Material:   

*Generalized Additive Models/Relationship between historic vegetation and climate/soil variables*

Gam model selection for the model with the lowest AIC value yeilded the model: tree density ~ s(MAP) + s(mean annual temperatue) + s(deltaT) + s(deltaP) + s(sandpct) + s(awc). While AIC suggests this is the best model (Table 1), it only explains 61% of the Deviance and has high Mean squared prediction error for predicting the test data set (MSPE = 5976.366). Prediction of tree density is overestimated in low tree denisty grid cells and underestimated in high tree denisty grid cells.  

The Gam model for the modern landscape explained only 29 % of the deviance and had a high mean squared prediction error for predicting the test data set (MSPE = XXXX). Prediction of tree density is again overestimated in low tree denisty grid cells and underestimated in high tree density grid cells. 


## Supplemental Methods:
*Public Land Survey Data:*
The Public Land Survey was commissioned by the U.S. General Land Office to assess the quality of land/timber and assign land titles for Euro-american settlers. The surveyors placed corner posts at 1 mile section corners in a grid within each township. At these section corners, and at 1/4 section corners, the surveyors would record the distance and azimuth from the corner to the nearest two trees, the species of the nearest two trees, and the diameter at breast height (DBH) of those trees. After these historic records were digitized (cite Mladenoff et al. ), we estimate the denisty and basal area at each corner point using the unbiased morista density estimator with correction factors for surveyor bias (@goring_2016, CITE Cogbill). Tree density is averaged across 8km x 8km grid cells in the upper Midwest.

*Forest Inventory Analysis Data:*

Add FIA data methods from Sean/Simon/Jack. FIA estimated tree denisty is also aggregated to the same 8km raster grid resolution.

*Climate Data*

  Mean annual temperature and Mean annual Precipitation data for the modern and historic vegetation-climate relationships are from PRISM datasets. Modern mean annual temperature and precipitation fore each 8km grid cell is calculated from the 800m 30-year Normals dataset. Historical climate is estimated as the average annual Temperature and average annual Precipiation over the 1895-1910 period. While this historical climate period does not overlap with the entirety of the European agricultural settlement era, this climatic period is the oldest for which we have reliable estimates of temperature and precipitation in the region. Precipitation seasonality was calculated from Monthly Prism datasets as follows: 

SI = sum 1-12(abs(mi - P/12))/P * 100

Temperature is calculated using the coefficient of variation method
TSI = sd(m1....m12)/Tavgannual *100
 
  
*Soil data*

  Soils data are derived from statewide gSSURGO 10m raster data product (<https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/home/?cid=NRCS142P2_053628>).  The weighted averages from the top 30cm of the soil were calculated for % sand, available water content (awc), and saturated hydraulic conductivity (ksat) soil parameters using the gSSURGO On-Demand ArcGIS toolbox (<https://github.com/ncss-tech/ssurgoOnDemand.git>). Weighted averages were calculated on the statewide soil raster datasets for Minnesota, Michigan, Wisconsin, Indiana, and Illinois, then weighted average rasters were mosaicked together to produce one single raster dataset. Maps of soil parameters were then aggregated to a 1km grid scale and an 8km Great Lakes St. Lawrence projected grid scale (PalEON dataset scale).

*Pricipal Component Analysis*

Since many climate and soils variables are often correlated, a pricipal components analysis was conducted to reduce dimensions and co-linearity in the environmental data. PCA was coducted on the scaled variables of historic MAP, historic Mean temperature, historic Precipitation Seasonality Index, Historic Tempearture Seasonality, AWC, and %sand. The modern principal component scores for climatic and soil variables were predicted using the historic principal component model. This method maintains the PCA of modern and historic environmental data on the same scale. The 1st Principal Component (PC1) was then used as a covariate when assessing bimodality. 

  
*Bimodality analysis*

Criteria for bimodality uses a both a bimodality coefficient (BC) and Hartigans Diptest for unimodality. Bimodality Coefficient is calculated from size, skewness, and kurtosis of the distributions (Pfister et al. 2013). A BC greater than 0.556 suggests bimodality. Bimodality coefficient (BC) is calculated from the distribuiton of data as follows using the R package 'modes':

BC = $\frac{(skew^2 + 1)}{(kurtosis + 3)*\frac{(n-1)^2}{(n-2)*(n-3)}}$

Desnity distributions of the PLS and FIA data were estimated. We then calculated the BC and performed Hartigan's diptest for unimodaltity for the on these smoothed density distribuitons for the PLS and FIA overall, and the BC within different bins of precipitation and the 1st Principal Component. Hartigan's diptest has a null hypothesis of a unimodal distribution of the data (CITE). This provides one BC value for a given range of precipitation/PC and whether the distribution is significantly different from a unimodal distribution. These ranges are used to determine the climate space where savannas and closed forests coexist.  

*Generalized Additive Models*

In addition to evaluating the BC for ranges of data, we developed several generalized additive models (GAMs) to determine if tree density can be deterministically predicted by climate and/or soils. GAMs were developed with both strictly additive terms and with flexible smooth terms. The full PLS data and FIA data were separated into two random halves that make up the testing and training datasets. GAM's were developed with the training dataset, and prediction error was estimated using the test dataset. Model parsimony was evaluated basing on AIC values, and model fit was assessed using RMSE. 

*Future Forest Stability under CMIP5 projected climate scenarios*

To investigate the consequences of the modern climate-vegetation relationship, and the past climate-vegetation relatiohsip would have for the stability of future midwestern forests, we utilized climate projections from CMIP5 representative concentration pathways (rcps) 2.6, 4.5, and 8.5. We obtained average monthly precipitation, total annual precipitation, average monthly temperature, and average annual temperature projections for 2070-2099 under the three RCP scenarios from the CCESM4 GCM climate downscaled climate projections (from worldclim, cite). We calculated precipitation and temperature seasonality as described above. Principal componenet scores (based on the past climate PCA) were assigned for each grid cell using the projected climate data from each RCP. 

We then identified the climate space (within PC1) that was bimodal in the PLS time, and mapped where this climate space is projected to be in 2070-2100. We also identified the climate space where FIA forests were bimodal on the modern landscape, and where this climate space would be in 2070-2100.



## Discussion:

  Tree density in the past was significantly bimodal, and was not accounted for by climate or soil factors, supporting our hypothesis that savannas and forests were alternative stable states in the region.  Projecting the past climate-vegeation relationship onto the modern climate would drive shifts in the climate space where bistable tree distributions are possible, but continue to predict large extent of savanna and forest alternative stable states on the modern landscape. However, modern tree density is no longer bimodal on the modern landscape, suggesting an unexpected shift towards stable closed forests in the region. Neither past tree density nor modern tree density has a fully deterministic relationship with climate, but bimodality in past tree density is predominant at intermediate temperature and precipitation space.  These largescale shifts from alternative savanna and forest stable states towards stable closed forests indicate that land use changes (fire suppression, logging, agricultural conversion) have had a far greater impact on midwestern woody ecosystems than changes in climate over the last ~150 years.  
  
  Land use changes that have led to fire suppression and land conversion in the region have long been hypothesized to drive "mesophication" (Nowacki and Abrams 2008), and increases in woody cover in the region. Additionally, small scale studies indicate that historic geography that would act as fire breaks (rivers and topography) are important explanatory variables for PLS vegetation (Grimm 1984). Modern land management strategies for restoring open savannas and grasslands in the region require extensive cutting and prescribed burns to limit understory tree growth (CITE). (CITE) suggest that a shift in overall fire return intervals have shifted southern midwest savanna and grasslands towards mesophytic forests and require larger and longer efforts of prescribed burns to return these ecosystems to their open states. While there has been small scale evidence that fire and disturbances were historically important for the maintence of temperate savanna-forest boundary in the US, our study is the first to document evidence for alternative savanna and forest stable states across a large region of the midwest. Additionally, the modern landscape after long term land use changes and post-settlement fire suppression has become mostly stable forests. 
  
  Evidence for alternative savanna and forest stable states in the temperate Midwest provides evidence that bistable systems are not constricted to the tropics. In the tropics, intermediate precipitation and high precipiation seasonality is the climatic domain for alternative stable states. However, our finding of temperate alternative stable states at much lower precipitaiton levels and temperatures, indicate that the constraints on growth identified in the tropics do not impose hard limits on the extent of these systems globally. Rather, we propose that alternative stable states are constrained to regions of intemediate moisture, where disturbance feedbacks occur. 

  Overall the shifts between the modern landscape and the pre-European settlement is marked by large scale forest stabilization, a shift from bimodal distribution in tree cover characterized by closed forests and open savannas, to mostly closed forested ecosystems. Throughtout the holocene, shifts in tree composition and tree cover have been linked to climatic variability across the region (CITE). However, this recent shift is not predicted by the observed changes in temperature, precipitation, or T/P seasonality. Rather, we propose that increased fire suppression and removal of disturbances from the landscape as likely mechanisms for overall shift towards closed forests. However, lack of direct evidence for the mechanism of these shifts makes it difficult to direct attribute the cause. Additonally, increases in atmospheric CO2 have been hypothesized to have a CO2 fertilization effect on tree growth, and could increase forest cover by increasing growth and tree recruitment (Wycoff and Bowers, CITE recruitment paper). To determine how much a CO2 fertilization effect may have contributed to increased forest cover in the Midwest, mechanistic evidence for CO2 fertilization in the region is needed. 
  
  The distribution of tree density across the region and the stabiliity of ecosystems to envrionmental changes can have large consequences for future biodiversity, carbon storage, and management decisions. Although evidence for alternative savanna and forest stable states in the midwest and throughout the globe suggest the potential for large scale forest/biome instability with changes in climate, ongoing land use changes and fires suppression have historically stabilized forests in the midwest. While increased stability of terrestrial ecosytems is a positive effects of the "mesophication" and overall conversion of savannas and grasslands to forests, it may come at the large cost of species biodiversity loss, increased vegetation homogenity, and loss of habitat. Assuming current land cover strategies continue, the modern forests are not likely to revert back to savanna in response of climate. However, increased likelihood of fire disturbances and further land use changes that may accompany changes in climate could alter the stability of the region. Being able to identify forest stability, and vegetation responses to different types of environmental changes will be important to understanding the trajectory of future forest and savanna biomes.  
  





# Supplemental Figures:
Additionally, the biplot for the Principal Components Analysis:
![](outputs/v1.6-5/full/pca_biplot.png)



# Climate space where the bimodality occurs: (3d plots):

![](outputs/3d_1.png)
![](outputs/3d_2.png)

We predict the binomial probability of having closed forest (tree density over 47 trees/hectare) given precipation, temperature, precip seasonality, temperature seasonality, % sand and awc. We get a decrease in probability of forests predicted in the open savanna regions, but the places with intermediate probability suggest unstable intermediates where savannas and forests are equally probable given the environmental data.


![](outputs/v1.6-5/full/logistic_pred_prob_testdata.png)

Here is the mapped distribution if we used the whole dataset (note this includes both training and testing dataests, I just wanted to look at a non-pixelated map)

![](outputs/v1.6-5/full/logistic_pred_prob_full.png)

# Tables with GAM model fits for PLS grid cells where we document unimodal distributions in tree cover:

# Issues with the GAM models: some models are predicting a few grid cells to be negative density (at the tails). Likely due to gaussian distn. family that was picked. The GLM models do not predict the negative density values, but still underestimate the low denisty places

Table 1: PLS density GAM models for stable sites
```{r, echo = FALSE, warning = FALSE}

suppressMessages(library(mgcv))
suppressMessages(library(caTools))
suppressMessages(library(ggplot2))
suppressMessages(library(MASS))

#dens.pr <- read.csv("data/midwest_pls_density_pr_alb1.6-5.csv") # just with grid cells that have both pls & FIA
#dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") # full set of PLS data
#hist(dens.pr$PLSdensity, breaks = 50)
#dens.pr <- read.csv("data/PLS_full_dens_pr_with_bins.csv")

dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/outputs/PLS_full_dens_pr_bins_with_bimodality_for_PC1.csv") 



pls.new <- dens.pr[dens.pr$bimodal == "Stable",] # remove all bimodal places for now
pls.bimodal <- dens.pr[dens.pr$bimodal == "Bimodal",]

pls.new <- pls.new[pls.new$PLSdensity > 0.5, ]# remove all zero places
dens.pr <- pls.new
dens.pr <- pls.new

# split into test and training datasets:
Y <- dens.pr$PLSdensity
msk <- sample.split( Y, SplitRatio = 1/4, group = NULL )
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]

#ggplot(dens.pr, aes(x = MAP1910, y = PLSdensity))+geom_point()
#ggplot(dens.pr, aes(x = MAP1910, y = pasttmean, color = PLSdensity))+geom_point()

# basic climate plots of data with only "stable forests/savannas"
PLS.gam1 <-gam(PLSdensity ~ MAP1910, data = train)
PLS.gam1L <-gam(PLSdensity ~  MAP1910, data = train)

pr <- predict(PLS.gam1L, test)
#summary(pr)
#plot(pr, test$PLSdensity)

PLS.gam2 <- gam(PLSdensity ~ s(pasttmean) , data = train)
PLS.gam2L <- gam(PLSdensity ~ pasttmean , data = train)
#summary(PLS.gam2) #explains 15.8% deviance
#plot(PLS.gam2)

PLS.gam3 <- gam(PLSdensity ~ s(pastdeltaP),data = train)
PLS.gam3L <- gam(PLSdensity ~ pastdeltaP,data = train)
#summary(PLS.gam3) #explains 6.07% deviance

PLS.gam4 <- gam(PLSdensity ~ s(deltaT), data = train)
PLS.gam4L <- gam(PLSdensity ~ deltaT, data = train)
#summary(PLS.gam4) #explains 6.07% deviance

PLS.gam5 <- gam(PLSdensity ~ s(awc),data = train)
PLS.gam5L <- gam(PLSdensity ~ awc, data = train)
#summary(PLS.gam5) #explains 12.5% of deviance

PLS.gam6 <- gam(PLSdensity ~ s(sandpct), data = train)
PLS.gam6L <- gam(PLSdensity ~ sandpct, data = train)
#summary(PLS.gam6) #explains 12.5% of deviance



PLS.gam7 <- gam(PLSdensity ~ s(pasttmean) + s(MAP1910) , data = train)
PLS.gam7L <- gam(PLSdensity ~ pasttmean + MAP1910 ,  data = train)
#summary(PLS.gam7) #explains 41% deviance


PLS.gam8 <- gam(PLSdensity ~ s(awc) +s(sandpct), data = train )
PLS.gam8L <- gam(PLSdensity ~ awc + sandpct, data = train )
#summary(PLS.gam8) #explains 28% of deviance

PLS.gam9 <- gam(PLSdensity ~ s(MAP1910) + s(pasttmean) + s(sandpct), data = train)
PLS.gam9L <- gam(PLSdensity ~ MAP1910 + pasttmean + sandpct, data = train)
#summary(PLS.gam9) #explains 39% deviance
#summary(PLS.gam9L)
#plot(PLS.gam6)


PLS.gam10 <- gam(PLSdensity ~ s(MAP1910) +s(pasttmean) + s(awc), data = train)
PLS.gam10L <- gam(PLSdensity ~ MAP1910 + pasttmean + awc, data = train)

#summary(PLS.gam10) #explains 41.3% of deviance
#plot(PLS.gam10)

PLS.gam11 <- gam(PLSdensity ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), data = train)
PLS.gam11L <- gam(PLSdensity ~ MAP1910  + pasttmean + sandpct + awc, data = train)

#summary(PLS.gam8) # explains 41% of deviance
PLS.gam12 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam12L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT, data = train)

PLS.gam14 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct), data = train)
PLS.gam14L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT + pastdeltaP + sandpct, data = train)

PLS.gam15 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), data = train, family = gaussian(link = 'identity'))
PLS.gam15L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT + pastdeltaP +sandpct + awc, data = train)

t <- predict(PLS.gam15, test[,c("PLSdensity", "MAP1910", "pasttmean", "deltaT", 'pastdeltaP', 'sandpct', 'awc')])
summary(t)

plot(t, test$PLSdensity)
abline (a = 0, b = 1, col = 'red')
hist(t)
hist(test$PLSdensity)

PLS.gam16 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP), data = train)
PLS.gam16L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT + pastdeltaP, data = train)

AIC.df<- AIC(PLS.gam1, PLS.gam2, PLS.gam3, PLS.gam4, PLS.gam5, PLS.gam6, PLS.gam7, PLS.gam8, PLS.gam9,PLS.gam10,PLS.gam11,PLS.gam12,PLS.gam13,PLS.gam14 ,PLS.gam15,PLS.gam16, PLS.gam1L, PLS.gam2L, PLS.gam3L, PLS.gam4L, PLS.gam5L, PLS.gam6L, PLS.gam7L, PLS.gam8L, PLS.gam9L, PLS.gam10L,PLS.gam11L,PLS.gam12L,PLS.gam13L,PLS.gam14L,PLS.gam15L, PLS.gam16L)

#AIC.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC.df$formula <- c(PLS.gam1$formula, PLS.gam2$formula, PLS.gam3$formula, PLS.gam4$formula, PLS.gam5$formula, PLS.gam6$formula, PLS.gam7$formula, PLS.gam8$formula, PLS.gam9$formula,PLS.gam10$formula,PLS.gam11$formula,PLS.gam12$formula,PLS.gam13$formula,PLS.gam14$formula ,PLS.gam15$formula ,PLS.gam16$formula , PLS.gam1L$formula, PLS.gam2L$formula, PLS.gam3L$formula, PLS.gam4L$formula, PLS.gam5L$formula, PLS.gam6L$formula, PLS.gam7L$formula, PLS.gam8L$formula, PLS.gam9L$formula, PLS.gam10L$formula,PLS.gam11L$formula,PLS.gam12L$formula,PLS.gam13L$formula, PLS.gam14L$formula, PLS.gam15L$formula,PLS.gam16L$formula)

AIC.df<- AIC.df[order(AIC.df$AIC),]
library(knitr)
library(pander)
AIC.df$model <- rownames(AIC.df)

#calculate prediction error:
msqe<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$PLSdensity - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC.df$dev.expl <- 1

#add prediction error & Deviance Explained to the AIC dataframe

for (i in 1: length(AIC.df$model)){
AIC.df[i,'MSPE'] <- msqe(get(AIC.df[i,"model"]), test)
AIC.df[i,"dev.expl"] <- summary(get(AIC.df[i,"model"]))$dev.expl * 100
}

#pander(AIC.df[,c("model", "formula", "df", "AIC", "MSPE", "dev.expl")], split.cells = 30)

print(AIC.df)

```



Table 2: FIA density GAM models
```{r, echo = FALSE, warning = FALSE}

suppressMessages(library(mgcv))
suppressMessages(library(caTools))
suppressMessages(library(ggplot2))

#dens.pr <- read.csv("data/midwest_pls_density_pr_alb1.6-5.csv") # just with grid cells that have both pls & FIA
#dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") # full set of PLS data
#hist(dens.pr$PLSdensity, breaks = 50)
#dens.pr <- read.csv("data/PLS_full_dens_pr_with_bins.csv")

fiadens <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/dens_pr_PLS_FIA_with_cov.csv")

fiadens <- fiadens[fiadens$FIAdensity > 47, ]
#split FIA data into test and trainfing datasets
Y <- fiadens$FIAdensity
msk <- sample.split( Y, SplitRatio = 1/4, group = fiadens$fiaecotype )
#table(Y,msk)

trainf <- fiadens[msk,]
testf <- fiadens[!msk,]


FIA.gam1 <-gam(FIAdensity ~  s(MAP2011), data = trainf)
FIA.gam1L <-gam(FIAdensity ~  MAP2011, data = trainf)


FIA.gam2 <- gam(FIAdensity ~ s(modtmean) , data = trainf)
FIA.gam2L <- gam(FIAdensity ~ modtmean , data = trainf)
#summary(FIA.gam2) #explains 5.6% deviance
#plot(FIA.gam2)

FIA.gam3 <- gam(FIAdensity ~ s(moderndeltaP), data = trainf)
FIA.gam3L <- gam(FIAdensity ~ moderndeltaP, data = trainf)
#summary(FIA.gam3) #explains 6.07% deviance

FIA.gam4 <- gam(FIAdensity ~ s(moddeltaT), data = trainf)
FIA.gam4L <- gam(FIAdensity ~ moddeltaT, data = trainf)
#summary(FIA.gam4) #explains 6.07% deviance

FIA.gam5 <- gam(FIAdensity ~ s(awc),data = trainf)
FIA.gam5L <- gam(FIAdensity ~ awc, data = trainf)
#summary(FIA.gam5) #explains 12.5% of deviance

FIA.gam6 <- gam(FIAdensity ~ s(sandpct), data = trainf)
FIA.gam6L <- gam(FIAdensity ~ sandpct, data = trainf)
#summary(FIA.gam6) #explains 12.5% of deviance



FIA.gam7 <- gam(FIAdensity ~ s(modtmean) + s(MAP2011) , data = trainf, family = quasipoisson())
FIA.gam7L <- gam(FIAdensity ~ modtmean + MAP2011 ,  data = trainf)
#summary(FIA.gam7) #explains 41% deviance
#summary(FIA.gam7L) # explains 19.6%

FIA.gam8 <- gam(FIAdensity ~ s(awc) +s(sandpct), data = trainf )
FIA.gam8L <- gam(FIAdensity ~ awc + sandpct, data = trainf )
#summary(FIA.gam8) #explains 28% of deviance

FIA.gam9 <- gam(FIAdensity ~ s(MAP2011) + s(modtmean) + s(sandpct), data = trainf)
FIA.gam9L <- gam(FIAdensity ~ MAP2011 + modtmean + sandpct, data = trainf)
#summary(FIA.gam9) #explains 39% deviance
#summary(FIA.gam9L)
#plot(FIA.gam6)


FIA.gam10 <- gam(FIAdensity ~ s(MAP2011) +s(modtmean) + s(awc), data = trainf)
FIA.gam10L <- gam(FIAdensity ~ MAP2011 + modtmean + awc, data = trainf)

#summary(FIA.gam10) #explains 41.3% of deviance
#plot(FIA.gam10)

FIA.gam11 <- gam(FIAdensity ~ s(MAP2011)  +s(modtmean) +s(sandpct) + s(awc), data = trainf)
FIA.gam11L <- gam(FIAdensity ~ MAP2011  + modtmean + sandpct + awc, data = trainf)

#summary(FIA.gam8) # explains 41% of deviance
FIA.gam12 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moderndeltaP), data = trainf)
FIA.gam12L <- gam(FIAdensity ~ MAP2011  + modtmean + moderndeltaP, data = trainf)

FIA.gam13 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moderndeltaP), data = trainf)
FIA.gam13L <- gam(FIAdensity ~ MAP2011  + modtmean + moderndeltaP, data = trainf)

FIA.gam13 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT), data = trainf)
FIA.gam13L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT, data = trainf)

FIA.gam14 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT) + s(moderndeltaP)+s(sandpct), data = trainf)
FIA.gam14L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT + moderndeltaP, data = trainf)

FIA.gam15 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT) + s(moderndeltaP)+s(sandpct)+s(awc), data = trainf)
FIA.gam15L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT + moderndeltaP, data = trainf)

FIA.gam16 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT) + s(moderndeltaP), data = trainf)
FIA.gam16L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT + moderndeltaP, data = trainf)

AICf.df<- AIC(FIA.gam1, FIA.gam2, FIA.gam3, FIA.gam4, FIA.gam5, FIA.gam6, FIA.gam7, FIA.gam8, FIA.gam9,FIA.gam10,FIA.gam11,FIA.gam12,FIA.gam13,FIA.gam14 ,FIA.gam15,FIA.gam16, FIA.gam1L, FIA.gam2L, FIA.gam3L, FIA.gam4L, FIA.gam5L, FIA.gam6L, FIA.gam7L, FIA.gam8L, FIA.gam9L, FIA.gam10L,FIA.gam11L,FIA.gam12L,FIA.gam13L,FIA.gam14L,FIA.gam15L, FIA.gam16L)

#AIC.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AICf.df$formula <- c(FIA.gam1$formula, FIA.gam2$formula, FIA.gam3$formula, FIA.gam4$formula, FIA.gam5$formula, FIA.gam6$formula, FIA.gam7$formula, FIA.gam8$formula, FIA.gam9$formula,FIA.gam10$formula,FIA.gam11$formula,FIA.gam12$formula,FIA.gam13$formula,FIA.gam14$formula ,FIA.gam15$formula , FIA.gam16L$formula, FIA.gam1L$formula, FIA.gam2L$formula, FIA.gam3L$formula, FIA.gam4L$formula, FIA.gam5L$formula, FIA.gam6L$formula, FIA.gam7L$formula, FIA.gam8L$formula, FIA.gam9L$formula, FIA.gam10L$formula,FIA.gam11L$formula,FIA.gam12L$formula,FIA.gam13L$formula, FIA.gam14L$formula, FIA.gam15L$formula, FIA.gam16L$formula )

AICf.df<- AICf.df[order(AICf.df$AIC),]
library(knitr)
library(pander)
AICf.df$model <- as.character(rownames(AICf.df))

#calculate prediction error:
msqe.f<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$FIAdensity - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AICf.df$MSPE <- 1
AICf.df$dev.expl <- 1

#add prediction error of AIC dataframe

for (i in 1: length(AICf.df$model)){
AICf.df[i,'MSPE'] <- msqe.f(get(AICf.df[i,"model"]), testf)
AICf.df[i,"dev.expl"] <- summary(get(AICf.df[i,"model"]))$dev.expl * 100
}

print(AICf.df)
#print(AICf.df[,c("model", "formula", "df", "AIC", "MSPE")], split.cells = 30)

```


###Predicting Tree density (GAMs)

The model with the lowest AIC value is represented by the formula:
PLSdensity ~ s(MAP) + s(MAT) + s(TempCV) + s(PrecipSI) + s(% sand) + s(awc)

Addtionally, for the FIA dataset the model with the lowest AIC also includes MAP, MAT, TempCV, PrecipSI, % sand, and awc. However, the model fits for the modern landscape are substantially lower.

# Supplemental PLS density model fit figures:
```{r, echo = FALSE, warning = FALSE}
suppressMessages(library(maps))
suppressMessages(library(sp))
suppressMessages(library(rgeos))
suppressMessages(library(visreg))
suppressMessages(library(grid))
all_states <- map_data("state")
states <- subset(all_states, region %in% c(  'minnesota','wisconsin','michigan',"illinois",  'indiana') )
coordinates(states)<-~long+lat
class(states)
proj4string(states) <-CRS("+proj=longlat +datum=NAD83")
mapdata<-spTransform(states, CRS('+init=epsg:3175'))
mapdata <- data.frame(mapdata)
cbpalette <- c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837")
#map out 


# plot the predicted response fields to these variables
# make a function to extracted predictions from a model
get.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")

testdata$ypred <- ypred

testdata
}

# for the PLS:
predicted <- get.preds(PLS.gam16, test)
#summary(predicted$ypred)

# for the PLS bimodal only places
predictedbm <- get.preds(PLS.gam16, pls.bimodal)

#summary(predictedbm$ypred)


msqe<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$PLSdensity - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

msqe(PLS.gam15L, test)
msqe(PLS.gam15L, pls.bimodal)



# predictions for FIA
predictedf <- get.preds(FIA.gam15, testf)
summary(predictedf$ypred)


####################################
# Plotting predicted vs. observed ##
####################################

# Define function to plot predicted vs. observed:
pvsobs <- function(preds, obs, colorby, model ){
# plot predicted vs. observed for PLS
ggplot(preds, aes(preds[,obs], ypred, color = preds[,colorby])) +geom_point() + theme_bw()+geom_abline(intercept = 0, slope = 1, color = 'red', size = 2) + #ylim (-10, 600)+xlim(-10,600) +
  ggtitle(paste('Predicted vs. Observed', model)) + ylab('Predicted tree density') + xlab('Observed tree density')
}

# plot predicted vs. observed for PLS model 15
pvsobs(preds = predicted, obs = 'PLSdensity', colorby = "PC1", model = "PLS density")

# plot predicted vs. observed for PLS model 15
pvsobs(preds = predictedbm, obs = 'PLSdensity', colorby = "PC1", model = "PLS density Bimodal only places")


# plot FIA predicted vs. observed model 15
pvsobs(preds = predictedf, obs = 'FIAdensity', colorby = "PC1", model = "FIA density")


```
The predicted vs. observed plot shows overestimation of PLS tree density in Low density areas and underestimation of PLS tree density in High density areas. Below we map out the predictions and prediction errors in space. Model fit has improved for the stable portions of the PLS landscape, and does an Okay job predicting PLS tree density. Note that the predictions here are overall much higher than the observations for FIA tree denisty. 


 # Map out predictions in space:
```{r, echo = FALSE, warning = FALSE}

# Creat a function to plot the predicted tree denisty in the map
map.preds <- function(preds, model){
ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=preds, aes(x=x, y=y, fill = ypred))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title=paste("Predicted", model)) + 
  scale_fill_gradientn(colours = c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837"), limits = c(0,700), name ="Tree \n Density \n (trees/hectare)", na.value = 'darkgrey') +
  coord_equal()+theme_bw()
  
}

map.preds(preds = predicted, model = "PLS denisty")
map.preds(preds = predictedbm, model = "PLS denisty bimodal only")

map.preds(preds = predictedf, model = "FIA denisty")


```

#Mapping out predicted - observed for each grid cell in the test dataset. 

```{r, echo = FALSE,  warning = FALSE}

suppressMessages(library(RColorBrewer))

# function to calculate discrete bins of model error
diserror.map<- function (preds, obs, model){
# calculate preds - observed
preds$podiff <- preds[,'ypred'] - preds[,obs]

Sd = rep(0,length(preds$podiff))
  Sd[which(preds$podiff>0 & preds$podiff<=10)] = 1
  Sd[which(preds$podiff>10 & preds$podiff<=50)] = 2
  
  Sd[which(preds$podiff>50 & preds$podiff<=100)] = 3
  Sd[which(preds$podiff>100) ] = 4
  Sd[which(preds$podiff== 0)] = 0
   Sd[which(preds$podiff>=-10 & preds$podiff<0)] = -1
  Sd[which(preds$podiff>-50 & preds$podiff<=-10)] = -2
  
  Sd[which(preds$podiff> -100 & preds$podiff<=-50)] = -3
  Sd[which(preds$podiff< -100) ] = -4
  Sd = factor(Sd,levels=-4:4)
  levels(Sd) = c(">-100","(-100,-50]","(-50, -10]","(-10,0]",'0','(0,10]','(10,50]','(50, 100]','(100,200]')
  
  preds$errordiscrete <- Sd
  
 gs.pal <- colorRampPalette(brewer.pal(11,"PRGn"))


# map out preds - observed using discrete scale
ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=preds, aes(x=x, y=y, fill = errordiscrete))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title=paste("Predicted - Obs", model)) +scale_fill_manual(values=gs.pal(9),drop=FALSE) +
  coord_equal()+theme_bw()
}

diserror.map ( preds = predicted, obs = "PLSdensity", model = "PLS density")

diserror.map ( preds = predictedbm, obs = "PLSdensity", model = "PLS bimodal places")


diserror.map ( preds = predictedf, obs = "FIAdensity", model = "FIA density")


```



# Plot the predicted - observed by veg class
```{r, echo = FALSE,  warning = FALSE}
suppressMessages(library(modes))
suppressMessages(library(gridExtra))

class.plots<- function(preds, obs, class){
preds$podiff <- preds[,'ypred'] - preds[,obs]

a <- ggplot(preds, aes(x = preds[,class], y = podiff))+geom_boxplot()+xlab("Predicted - Observed for different Bimodal regions")+theme_bw()

b <- ggplot(preds, aes(x = podiff)) + geom_vline( aes(xintercept=0), colour="red") +geom_histogram()+facet_grid(preds[,class]~., scales = 'free') + xlab("Predicted - Observed for different Bimodal regions") + theme_bw()
grid.arrange(a,b, ncol = 1, nrow = 2)
}

class.plots(preds = predicted, obs = "PLSdensity", class = 'classification')
class.plots(preds = predictedbm, obs = "PLSdensity", class = 'classification')

class.plots(preds = predictedf, obs = "FIAdensity", class = 'fiaecotype')


```

# Plot predicted - obs against density:

```{r, echo = FALSE,  warning = FALSE}

plot.po.dens <- function(preds, obs, model){
preds$podiff <- preds[,'ypred'] - preds[,obs]
Sd = rep(0,length(preds$podiff))
  Sd[which(preds$podiff>0 & preds$podiff<=10)] = 1
  Sd[which(preds$podiff>10 & preds$podiff<=50)] = 2
  
  Sd[which(preds$podiff>50 & preds$podiff<=100)] = 3
  Sd[which(preds$podiff>100) ] = 4
  Sd[which(preds$podiff== 0)] = 0
   Sd[which(preds$podiff>=-10 & preds$podiff<0)] = -1
  Sd[which(preds$podiff>-50 & preds$podiff<=-10)] = -2
  
  Sd[which(preds$podiff> -100 & preds$podiff<=-50)] = -3
  Sd[which(preds$podiff< -100) ] = -4
  Sd = factor(Sd,levels=-4:4)
  levels(Sd) = c(">-100","(-100,-50]","(-50, -10]","(-10,0]",'0','(0,10]','(10,50]','(50, 100]','(100,200]')
  
  preds$errordiscrete <- Sd
  
 gs.pal <- colorRampPalette(brewer.pal(11,"PRGn"))

ggplot() + geom_point(data = preds, aes(x= preds[,obs], y = podiff, color = errordiscrete)) +scale_color_manual(values=gs.pal(9),name = "Pred-Obs",drop=FALSE)+ theme_bw() + xlab("Tree density")+ ylab("Predicted - Observed") + ggtitle(paste("Predicted - obs. vs.", model))
}

plot.po.dens(predicted, "PLSdensity", model = "PLS density")
plot.po.dens(predictedbm, "PLSdensity", model = "PLS density bimodal cells")

plot.po.dens(predictedf, "FIAdensity", model = "FIA density")

```
PLS model trained on the stable places results in high overpredictions for low tree denisty areas and moderate underprediction for tree density in high density grid cells. 

FIA models overpredict over the places that have low tree denisty. I think that if we remove the low denisty places, we might be able to better predict. 


## Predicting Forest vs. Savanna (not density)

The above models are predicting density (continious variable) from continous envrionmental and climate covariates. However, we can also use the savanna/forest density classificaitons as our y variable and  predict the probability a grid cell is forest (ecocode = 1, PLS density > 47 trees/ha) and savannna (ecocode = 0, PLSdensity < 47 trees/ha & >0.5 trees/ha) from continous environmental and climate covariates. 


This method has the benefit of predicting the probability of forest (or the probability of savanna) given certain environmental conditions. For this analysis, we exclude prairie sites

# Modeling p(forest):
```{r echo = FALSE, warning = FALSE}
dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") 



fiadens <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/dens_pr_PLS_FIA_with_cov.csv")

future <- fiadens[,c('x','y','FIAdensity', 'MAP2011', 'moderndeltaP', "modtmean", 'moddeltaT', 'sandpct','awc','ksat', 'fiaecotype')]

# rename future variables to match pls
colnames(future) <- c('x','y','PLSdensity', 'MAP1910', 'pastdeltaP', 'pasttmean', 'deltaT', "sandpct", "awc", "ksat",'fiaecotype')

# dummyvariables for logistic regression:
dens.pr$ecocode <- 0
dens.pr[dens.pr$ecotype %in% 'Forest', ]$ecocode <- 1
dens.pr<- dens.pr[!dens.pr$ecotype %in% 'prairie',]

future$ecocode <- 0
future[future$fiaecotype %in% 'Forest', ]$ecocode <- 1
future<- future[!future$fiaecotype %in% 'prairie',]


#split trainfing and testing
Y <- dens.pr$ecotype
msk <- sample.split( Y, SplitRatio = 3/4, group = NULL)
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]


#plot(dens.pr$sandpct, dens.pr$ecotype)


PLS.lgr1 <-gam(ecocode ~  s(MAP1910), family = 'binomial',data = train)
PLS.lgr1L <-gam(ecocode ~  MAP1910, family = 'binomial',data = train)


PLS.lgr2 <- gam(ecocode ~ s(pasttmean) , family = 'binomial',data = train)
PLS.lgr2L <- gam(ecocode ~ pasttmean , family = 'binomial',data = train)
#summary(PLS.lgr2) #explains 15.8% deviance
#plot(PLS.lgr2)

PLS.lgr3 <- gam(ecocode ~ s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr3L <- gam(ecocode ~ pastdeltaP, family = 'binomial',data = train)
#summary(PLS.lgr3) #explains 6.07% deviance

PLS.lgr4 <- gam(ecocode ~ s(deltaT), family = 'binomial',data = train)
PLS.lgr4L <- gam(ecocode ~ deltaT, family = 'binomial',data = train)
#summary(PLS.lgr4) #explains 6.07% deviance

PLS.lgr5 <- gam(ecocode ~ s(awc), family = 'binomial',data = train)
PLS.lgr5L <- gam(ecocode ~ awc, family = 'binomial',data = train)
#summary(PLS.lgr5) #explains 12.5% of deviance

PLS.lgr6 <- gam(ecocode ~ s(sandpct), family = 'binomial',data = train)
PLS.lgr6L <- gam(ecocode ~ sandpct, family = 'binomial',data = train)
#summary(PLS.lgr6) #explains 12.5% of deviance



PLS.lgr7 <- gam(ecocode ~ s(pasttmean) + s(MAP1910) ,  family = 'binomial',data = train)
PLS.lgr7L <- gam(ecocode ~ pasttmean + MAP1910 ,  family = 'binomial',data = train)
#summary(PLS.lgr7) #explains 41% deviance
#summary(PLS.lgr7L) # explains 19.6%

PLS.lgr8 <- gam(ecocode ~ s(awc) +s(sandpct), family = 'binomial',data = train )
PLS.lgr8L <- gam(ecocode ~ awc + sandpct, family = 'binomial',data = train )
#summary(PLS.lgr8) #explains 28% of deviance

PLS.lgr9 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = 'binomial',data = train)
PLS.lgr9L <- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = 'binomial',data = train)
#summary(PLS.lgr9) #explains 39% deviance
#summary(PLS.lgr9L)
#plot(PLS.lgr6)


PLS.lgr10 <- gam(ecocode ~ s(MAP1910) +s(pasttmean) + s(awc), family = 'binomial',data = train)
PLS.lgr10L <- gam(ecocode ~ MAP1910 + pasttmean + awc, family = 'binomial',data = train)

#summary(PLS.lgr10) #explains 41.3% of deviance
#plot(PLS.lgr10)

PLS.lgr11 <- gam(ecocode ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), family = 'binomial',data = train)
PLS.lgr11L <- gam(ecocode ~ MAP1910  + pasttmean + sandpct + awc, family = 'binomial',data = train)

#summary(PLS.lgr8) # explains 41% of deviance
PLS.lgr12 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP),family = 'binomial', data = train)
PLS.lgr12L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

#PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT), family = 'binomial',data = train)
#PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT, family = 'binomial',data = train)

PLS.lgr14 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), family = 'binomial',data = train)
PLS.lgr14L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT + pastdeltaP, family = 'binomial',data = train)

AIC2.df<- AIC(PLS.lgr1, PLS.lgr2, PLS.lgr3, PLS.lgr4, PLS.lgr5, PLS.lgr6, PLS.lgr7, PLS.lgr8, PLS.lgr9,PLS.lgr10,PLS.lgr11,PLS.lgr12,PLS.lgr13,PLS.lgr14 , PLS.lgr1L, PLS.lgr2L, PLS.lgr3L, PLS.lgr4L, PLS.lgr5L, PLS.lgr6L, PLS.lgr7L, PLS.lgr8L, PLS.lgr9L, PLS.lgr10L,PLS.lgr11L,PLS.lgr12L,PLS.lgr13L,PLS.lgr14L)




AIC2.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC2.df$formula <- c(PLS.lgr1$formula, PLS.lgr2$formula, PLS.lgr3$formula, PLS.lgr4$formula, PLS.lgr5$formula, PLS.lgr6$formula, PLS.lgr7$formula, PLS.lgr8$formula, PLS.lgr9$formula,PLS.lgr10$formula,PLS.lgr11$formula,PLS.lgr12$formula,PLS.lgr13$formula,PLS.lgr14$formula , PLS.lgr1L$formula, PLS.lgr2L$formula, PLS.lgr3L$formula, PLS.lgr4L$formula, PLS.lgr5L$formula, PLS.lgr6L$formula, PLS.lgr7L$formula, PLS.lgr8L$formula, PLS.lgr9L$formula, PLS.lgr10L$formula,PLS.lgr11L$formula,PLS.lgr12L$formula,PLS.lgr13L$formula, PLS.lgr14L$formula )

AIC2.df<- AIC2.df[order(AIC2.df$AIC),]
library(knitr)
library(pander)
AIC2.df$model <- rownames(AIC2.df)

#calculate prediction error:
msqe.code<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$ecocode - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC2.df$MSPE <- 1

#add prediction error ot AIC dataframe

for (i in 1: length(AIC2.df$model)){
AIC2.df[i,'MSPE'] <- msqe.code(get(AIC2.df[i,"model"]), test)
}
pander(AIC2.df[,c("model","modeltype", "formula", "df", "AIC", "MSPE")], split.cells = 30)


#full <- dens.pr
full <- test
logsample <- predict(PLS.lgr14, full, type="response")
full$ypred <- as.numeric(logsample)
#summary(logsample)
#hist(test$ypred)

#ggplot(full, aes(x, y, color = ypred)) + geom_point()
#ggplot(test, aes(x, y, color = ecocode)) + geom_point()+coord_equal()

#ggplot(test, aes(ypred, PLSdensity))+geom_point()

#ggplot(test, aes (ypred, MAP1910))+geom_point()



# create discrete probability cuts
label.breaks <- function(beg, end, splitby){
  labels.test <- data.frame(first = seq(beg, end, by = splitby), second = seq((beg + splitby), (end + splitby), by = splitby))
  labels.test <- paste (labels.test$first, '-' , labels.test$second)
  labels.test
}


full$ypreddiscrete <- cut(full$ypred, breaks = seq(0,1, by = 0.2), labels = label.breaks(0,0.8, 0.2))



cbpalette <- c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837")

full$ypreddiscrete <- as.character(full$ypreddiscrete)
#ggplot(full, aes(x, y, color = ypreddiscrete)) + geom_point()



# plot the discrete probability of forest 
p.forest <- ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=full, aes(x=x, y=y, fill = ypreddiscrete))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="Climate Predicted Prob(forest)")+ scale_fill_manual(values= cbpalette) +
  coord_equal()+theme_bw()+ theme()

# plot PLS forests
pls <- ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=full, aes(x=x, y=y, fill = ecotype))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="PLS classification")+ scale_fill_manual(values= c("#006837", "#c2e699"))+ coord_equal()+theme_bw()

png(width = 8, height = 4, units = 'in', res = 300, filename = 'outputs/v1.6-5/full/logistic_pred_prob_testdata.png')
grid.arrange(pls, p.forest, nrow = 1, ncol=2)
dev.off()




# use the pls model to model the modern landscape:
fia <- future
logsample <- predict(PLS.lgr14, fia, type="response")
fia$ypred <- as.numeric(logsample)
summary(logsample)
hist(fia$ypred)

ggplot(fia, aes(x, y, color = ypred)) + geom_point()
ggplot(fia, aes(x, y, color = ecocode)) + geom_point()+coord_equal()

ggplot(fia, aes(ypred, PLSdensity))+geom_point()

#ggplot(test, aes (ypred, MAP1910))+geom_point()



# create discrete probability cuts
label.breaks <- function(beg, end, splitby){
  labels.test <- data.frame(first = seq(beg, end, by = splitby), second = seq((beg + splitby), (end + splitby), by = splitby))
  labels.test <- paste (labels.test$first, '-' , labels.test$second)
  labels.test
}


fia$ypreddiscrete <- cut(fia$ypred, breaks = seq(0,1, by = 0.2), labels = label.breaks(0,0.8, 0.2))



cbpalette <- c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837")

fia$ypreddiscrete <- as.character(fia$ypreddiscrete)

# plot predictions for modern forests based on pls-climate relationships: 
# it actually predicts a contraction of the forests!
f.forest <- ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=fia, aes(x=x, y=y, fill = ypreddiscrete))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="Climate Predicted Prob(forest)")+ scale_fill_manual(values= cbpalette) +
  coord_equal()+theme_bw()+ theme()


mod <- ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=fia, aes(x=x, y=y, fill = fiaecotype))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="FIA classification")+ scale_fill_manual(values= c("#006837", "#c2e699"))+ coord_equal()+theme_bw()

png(width = 8, height = 4, units = 'in', res = 300, filename = 'outputs/v1.6-5/full/logistic_pred_prob_FIA_from_PLS_model.png')
grid.arrange(mod, f.forest, nrow = 1, ncol=2)
dev.off()

```

# modeling p(savanna)
```{r echo = FALSE, warning = FALSE}
dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") 

# dummyvariables for logistic regression:
dens.pr$ecocode <- 1
dens.pr[dens.pr$ecotype %in% 'Forest', ]$ecocode <- 0
dens.pr<- dens.pr[!dens.pr$ecotype %in% 'prairie',]

#split trainfing and testing
Y <- dens.pr$ecotype
msk <- sample.split( Y, SplitRatio = 3/4, group = NULL)
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]


#plot(dens.pr$sandpct, dens.pr$ecotype)


PLS.lgr1 <-gam(ecocode ~  s(MAP1910), family = 'binomial',data = train)
PLS.lgr1L <-gam(ecocode ~  MAP1910, family = 'binomial',data = train)


PLS.lgr2 <- gam(ecocode ~ s(pasttmean) , family = 'binomial',data = train)
PLS.lgr2L <- gam(ecocode ~ pasttmean , family = 'binomial',data = train)
#summary(PLS.lgr2) #explains 15.8% deviance
#plot(PLS.lgr2)

PLS.lgr3 <- gam(ecocode ~ s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr3L <- gam(ecocode ~ pastdeltaP, family = 'binomial',data = train)
#summary(PLS.lgr3) #explains 6.07% deviance

PLS.lgr4 <- gam(ecocode ~ s(deltaT), family = 'binomial',data = train)
PLS.lgr4L <- gam(ecocode ~ deltaT, family = 'binomial',data = train)
#summary(PLS.lgr4) #explains 6.07% deviance

PLS.lgr5 <- gam(ecocode ~ s(awc), family = 'binomial',data = train)
PLS.lgr5L <- gam(ecocode ~ awc, family = 'binomial',data = train)
#summary(PLS.lgr5) #explains 12.5% of deviance

PLS.lgr6 <- gam(ecocode ~ s(sandpct), family = 'binomial',data = train)
PLS.lgr6L <- gam(ecocode ~ sandpct, family = 'binomial',data = train)
#summary(PLS.lgr6) #explains 12.5% of deviance



PLS.lgr7 <- gam(ecocode ~ s(pasttmean) + s(MAP1910) ,  family = 'binomial',data = train)
PLS.lgr7L <- gam(ecocode ~ pasttmean + MAP1910 ,  family = 'binomial',data = train)
#summary(PLS.lgr7) #explains 41% deviance
#summary(PLS.lgr7L) # explains 19.6%

PLS.lgr8 <- gam(ecocode ~ s(awc) +s(sandpct), family = 'binomial',data = train )
PLS.lgr8L <- gam(ecocode ~ awc + sandpct, family = 'binomial',data = train )
#summary(PLS.lgr8) #explains 28% of deviance

PLS.lgr9 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = 'binomial',data = train)
PLS.lgr9L <- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = 'binomial',data = train)
#summary(PLS.lgr9) #explains 39% deviance
#summary(PLS.lgr9L)
#plot(PLS.lgr6)


PLS.lgr10 <- gam(ecocode ~ s(MAP1910) +s(pasttmean) + s(awc), family = 'binomial',data = train)
PLS.lgr10L <- gam(ecocode ~ MAP1910 + pasttmean + awc, family = 'binomial',data = train)

#summary(PLS.lgr10) #explains 41.3% of deviance
#plot(PLS.lgr10)

PLS.lgr11 <- gam(ecocode ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), family = 'binomial',data = train)
PLS.lgr11L <- gam(ecocode ~ MAP1910  + pasttmean + sandpct + awc, family = 'binomial',data = train)

#summary(PLS.lgr8) # explains 41% of deviance
PLS.lgr12 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP),family = 'binomial', data = train)
PLS.lgr12L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

#PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT), family = 'binomial',data = train)
#PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT, family = 'binomial',data = train)

PLS.lgr14 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), family = 'binomial',data = train)
PLS.lgr14L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT + pastdeltaP, family = 'binomial',data = train)

AIC2.df<- AIC(PLS.lgr1, PLS.lgr2, PLS.lgr3, PLS.lgr4, PLS.lgr5, PLS.lgr6, PLS.lgr7, PLS.lgr8, PLS.lgr9,PLS.lgr10,PLS.lgr11,PLS.lgr12,PLS.lgr13,PLS.lgr14 , PLS.lgr1L, PLS.lgr2L, PLS.lgr3L, PLS.lgr4L, PLS.lgr5L, PLS.lgr6L, PLS.lgr7L, PLS.lgr8L, PLS.lgr9L, PLS.lgr10L,PLS.lgr11L,PLS.lgr12L,PLS.lgr13L,PLS.lgr14L)




AIC2.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC2.df$formula <- c(PLS.lgr1$formula, PLS.lgr2$formula, PLS.lgr3$formula, PLS.lgr4$formula, PLS.lgr5$formula, PLS.lgr6$formula, PLS.lgr7$formula, PLS.lgr8$formula, PLS.lgr9$formula,PLS.lgr10$formula,PLS.lgr11$formula,PLS.lgr12$formula,PLS.lgr13$formula,PLS.lgr14$formula , PLS.lgr1L$formula, PLS.lgr2L$formula, PLS.lgr3L$formula, PLS.lgr4L$formula, PLS.lgr5L$formula, PLS.lgr6L$formula, PLS.lgr7L$formula, PLS.lgr8L$formula, PLS.lgr9L$formula, PLS.lgr10L$formula,PLS.lgr11L$formula,PLS.lgr12L$formula,PLS.lgr13L$formula, PLS.lgr14L$formula )

AIC2.df<- AIC2.df[order(AIC2.df$AIC),]
library(knitr)
library(pander)
AIC2.df$model <- rownames(AIC2.df)

#calculate prediction error:
msqe.code<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$ecocode - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC2.df$MSPE <- 1

#add prediction error ot AIC dataframe

for (i in 1: length(AIC2.df$model)){
AIC2.df[i,'MSPE'] <- msqe.code(get(AIC2.df[i,"model"]), test)
}
pander(AIC2.df[,c("model","modeltype", "formula", "df", "AIC", "MSPE")], split.cells = 30)

logsample <- predict(PLS.lgr14, test, type="response")
test$ypred <- logsample
summary(logsample)
hist(test$ypred)

ggplot(test, aes(MAP1910, ypred, color = ypred)) + geom_point()
ggplot(test, aes(x, y, color = ypred)) + geom_point()


```
Looks like model number 14 with just Mean Annual Precipitation has lowest AIC for the logistic/binomial model. 
Lets map out the probability of forest based on model with the lowest AIC value:

forest type ~ s(MAP1910)+ s(pasttmean) + s(deltaT) +   s(pastdeltaP)

The smooth predictors in this model are the same as the smooth predictors in the denisty model

# savanna forest model for FIA:
```{r echo = FALSE, warning = FALSE}

# dummyvariables for logistic regression:
fiadens$ecocode <- 0
fiadens[fiadens$ecotype %in% 'Forest', ]$ecocode <- 1
#fiadens<- fiadens[!fiadens$ecotype %in% 'prairie',]

#split trainffing and testfing
Y <- fiadens$ecotype
msk <- sample.split( Y, SplitRatio = 1/4, group = NULL )
#table(Y,msk)

trainf <- fiadens[msk,]
testf <- fiadens[!msk,]


#plot(fiadens$sandpct, fiadens$ecotype)


FIA.lgr1 <-gam(ecocode ~  s(MAP1910), family = 'binomial',data = trainf)
FIA.lgr1L <-gam(ecocode ~  MAP1910, family = 'binomial',data = trainf)


FIA.lgr2 <- gam(ecocode ~ s(pasttmean) , family = 'binomial',data = trainf)
FIA.lgr2L <- gam(ecocode ~ pasttmean , family = 'binomial',data = trainf)
#summary(FIA.lgr2) #explains 15.8% deviance
#plot(FIA.lgr2)

FIA.lgr3 <- gam(ecocode ~ s(pastdeltaP), family = 'binomial',data = trainf)
FIA.lgr3L <- gam(ecocode ~ pastdeltaP, family = 'binomial',data = trainf)
#summary(FIA.lgr3) #explains 6.07% deviance

FIA.lgr4 <- gam(ecocode ~ s(deltaT), family = 'binomial',data = trainf)
FIA.lgr4L <- gam(ecocode ~ deltaT, family = 'binomial',data = trainf)
#summary(FIA.lgr4) #explains 6.07% deviance

FIA.lgr5 <- gam(ecocode ~ s(awc), family = 'binomial',data = trainf)
FIA.lgr5L <- gam(ecocode ~ awc, family = 'binomial',data = trainf)
#summary(FIA.lgr5) #explains 12.5% of deviance

FIA.lgr6 <- gam(ecocode ~ s(sandpct), family = 'binomial',data = trainf)
FIA.lgr6L <- gam(ecocode ~ sandpct, family = 'binomial',data = trainf)
#summary(FIA.lgr6) #explains 12.5% of deviance



FIA.lgr7 <- gam(ecocode ~ s(pasttmean) + s(MAP1910) ,  family = 'binomial',data = trainf)
FIA.lgr7L <- gam(ecocode ~ pasttmean + MAP1910 ,  family = 'binomial',data = trainf)
#summary(FIA.lgr7) #explains 41% deviance
#summary(FIA.lgr7L) # explains 19.6%

FIA.lgr8 <- gam(ecocode ~ s(awc) +s(sandpct), family = 'binomial',data = trainf )
FIA.lgr8L <- gam(ecocode ~ awc + sandpct, family = 'binomial',data = trainf )
#summary(FIA.lgr8) #explains 28% of deviance

FIA.lgr9 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = 'binomial',data = trainf)
FIA.lgr9L <- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = 'binomial',data = trainf)
#summary(FIA.lgr9) #explains 39% deviance
#summary(FIA.lgr9L)
#plot(FIA.lgr6)


FIA.lgr10 <- gam(ecocode ~ s(MAP1910) +s(pasttmean) + s(awc), family = 'binomial',data = trainf)
FIA.lgr10L <- gam(ecocode ~ MAP1910 + pasttmean + awc, family = 'binomial',data = trainf)

#summary(FIA.lgr10) #explains 41.3% of deviance
#plot(FIA.lgr10)

FIA.lgr11 <- gam(ecocode ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), family = 'binomial',data = trainf)
FIA.lgr11L <- gam(ecocode ~ MAP1910  + pasttmean + sandpct + awc, family = 'binomial',data = trainf)

#summary(FIA.lgr8) # explains 41% of deviance
FIA.lgr12 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP),family = 'binomial', data = trainf)
FIA.lgr12L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = trainf)

FIA.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), family = 'binomial',data = trainf)
FIA.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = trainf)

#FIA.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT), family = 'binomial',data = trainf)
#FIA.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT, family = 'binomial',data = trainf)

FIA.lgr14 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), family = 'binomial',data = trainf)
FIA.lgr14L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT + pastdeltaP, family = 'binomial',data = trainf)

AIC2.df<- AIC(FIA.lgr1, FIA.lgr2, FIA.lgr3, FIA.lgr4, FIA.lgr5, FIA.lgr6, FIA.lgr7, FIA.lgr8, FIA.lgr9,FIA.lgr10,FIA.lgr11,FIA.lgr12,FIA.lgr13,FIA.lgr14 , FIA.lgr1L, FIA.lgr2L, FIA.lgr3L, FIA.lgr4L, FIA.lgr5L, FIA.lgr6L, FIA.lgr7L, FIA.lgr8L, FIA.lgr9L, FIA.lgr10L,FIA.lgr11L,FIA.lgr12L,FIA.lgr13L,FIA.lgr14L)




AIC2.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC2.df$formula <- c(FIA.lgr1$formula, FIA.lgr2$formula, FIA.lgr3$formula, FIA.lgr4$formula, FIA.lgr5$formula, FIA.lgr6$formula, FIA.lgr7$formula, FIA.lgr8$formula, FIA.lgr9$formula,FIA.lgr10$formula,FIA.lgr11$formula,FIA.lgr12$formula,FIA.lgr13$formula,FIA.lgr14$formula , FIA.lgr1L$formula, FIA.lgr2L$formula, FIA.lgr3L$formula, FIA.lgr4L$formula, FIA.lgr5L$formula, FIA.lgr6L$formula, FIA.lgr7L$formula, FIA.lgr8L$formula, FIA.lgr9L$formula, FIA.lgr10L$formula,FIA.lgr11L$formula,FIA.lgr12L$formula,FIA.lgr13L$formula, FIA.lgr14L$formula )

AIC2.df<- AIC2.df[order(AIC2.df$AIC),]
library(knitr)
library(pander)
AIC2.df$model <- rownames(AIC2.df)

#calculate prediction error:
msqe.code<- function(model, testfdata){
ypred <- predict(model, newdata = testfdata, type="response")
testfdata$ypred <- ypred

predicted<- testfdata
  
predicted$sqerr <- (predicted$ecocode - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC2.df$MSPE <- 1

#add prediction error ot AIC dataframe

for (i in 1: length(AIC2.df$model)){
AIC2.df[i,'MSPE'] <- msqe.code(get(AIC2.df[i,"model"]), test)
}
pander(AIC2.df[,c("model","modeltype", "formula", "df", "AIC", "MSPE")], split.cells = 30)


```
