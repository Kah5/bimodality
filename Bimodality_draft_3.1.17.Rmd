---
title: "Bimodality Paper Draft"
author: "Kelly Heilman"
date: "March 7th, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Science article (v. rough draft)


Stabilization of alternative stable states to closed forests after ~150 years of land use, climate change 

## Abstract (100- 150 words, no references)
* Opening question, background to the study (1-2), key results, concluding sentence*

How will vegetation with alternative stable states respond to environmental and climate changes? In many parts of the world, savanna and forests have been identified as alternate stable states, resulting in sharp transitions between savannas and forests in response to small spatial changes in environment. However, the responses of these systems to temperal environmental changes remains a key uncertainty in predictions for future vegetation distribution.
We analyzed both modern and historic tree density, climate, and soils data from the savanna forest boundary region in the North American Midwest to show that ~150 years of land use conversion, fire suppression, and climate shifts in the region have stabilized the region, converting historic savanna-forest alternative stable states into modern stable forests. These results identify climatic regions outside of the tropics where savanna and forest ecosystems are alternative stable states, and demonstrate that environmental changes have resulted in large scale stabilization of the region into a closed forest state. 


## Main Text:

  Environmental controls on tree density define the distribution of forested and open ecoystems worldwide, driving global patterns in woody carbon storage. Climate shifts, fires suppression, and land use changes may drive deterministic responses of tree density to these environmental changes, but non-deterministic relationships between tree density and environmental controls could result in divergent and non-linear shifts in tree density between multiple stable states. The response and sensitivity of transitions between alternative stable states at their "tipping points" represents a key uncertainty in modeling future responses to environmental changes. Savannas and forests are documented as alternative stable states at intemediate precipitation in the tropics, prompting concerns over potential large scale forest collapse in bistable regions. 
  
  However, the resilience of alternative stable states to changes in environmental variables have largely been identified by quantifying changes in vegetation and environmental parameters across space. This approach provides a snapshot understanding of the environmental space where savanna and forests co-occur and could be sensitive to environmental changes, but does not document the actual responses of altenative stable states to temporal changes in the environmental. To explore the potential responses of alternative stable states to future environmental changes, we use historic (pre-European Agricultural Settlement) and modern vegetation data from the North American savanna-forest boundary to ask whether savanna and forests are alternative stable states in the temperate zone and determine if these systems were resilient to large scale fire suppression, land use change, and shifts in climate over the last ~150 years in the region. 
  
  In the North American temperate zone, much of the savanna-forest boundary has transitioned into a closed forest state (non-agricultural landscape) (Nowaki and Abrams 208). This shift has occured over a time period of regional fire supppression at least since the 1930's (Nowacki & Abrams 2008), land use changes, and climatic shifts (CITE). We estimate pre-European agricultural settlement stem density across 5 states in the Upper Midwest using historical survey data collected in the 19th century (Public Land Survey (PLS)), and estimate modern stem density from Forest Inventory Analysis (FIA) vegetation surveys. We evaluate whether there is evidence of alternative stable states in the past by determining if the past landscape had a bimodal distribution of tree density that cannot be accounted for using climate or soils. We then assess how persistant the hypothesized alternative stable states are on the landscape by comparing the historic relationships between density, soils, and climate to the modern relationship of tree denisty to soils and climate. Finally, we apply the past and modern relationships with soils and climate to characterize the resilience to projected future climatic changes. We hypothesized that  PLS distribution of tree density was bimodal and not well explained by environmental factors due to latent intact vegetation-disturbance feedbacks along the savanna-forest boundary before settlement, but that ~150 years of land use fragmentation, climate changes, and fire suppression has stabilized modern vegetation as closed forests and produced a modern boundary that is not bimodal.

  Before European Agricultural settlement in the midwest, tree density in the past was significantly bimodal across the entire upper midwest, with prominant modes at low tree density (30 trees/ha) and at high tree density (205 trees/ha) (Diptest p < 0.05, BC = 0.74306, Figure 1). While Hartigan's diptest shows shows a significant multimodality to the Modern FIA tree denstity, the two modes both occur at intermediate and high tree denisty (147 trees/ha, and 550 trees/ha), which would both be classified as closed forest ecosystems (Anderson et al. (CITE)). Therefore, we do not see a significant bimodality with low and high tree density modes on the modern landscape (Figure 1). This shift in tree density distribution is well explained by the original tree density. Specifically, grid cells with historically low tree density have generally increased in tree denisity, while those that were dense closed forests in the past have decreased in tree density (Linear reg., R^2 = 0.4, p < 0.05, Figure 2- Difference fig). 

In the past, tree density could only be partially explained by climate. Low tree denisty occured at very low mean annual precipitaiton (600mm/year), but at intermediate precipitation between 700 - 1000 mm/year, both high and low tree densities are possible and form a significant bimodal distribution (PRSIM Mean annual precipitaiton 1885-1925). This suggests that for temperate savannas, very low moisture may serve as a low boundary condition for tree growth, but above this condition, moisture may not be the most important factor deterimining tree denisty. Moderate mean annual temperatures (5-11 degC) overlapped with the intermediate precipitation space where savannas and forests were possible. To determine if the bimodality in tree density could be explained by patterns in climate/edaphic factors, we evaluated tree density distributions over equal intervals of the 1st principal component (PC1) of all environmental variables. PC1 explains 54% of variance in the environmental covariates and past precipitation and Past Temperature both have strong positive loadings on PC1, while temperature seasonality (CV) and precipitation seasonality index (SI) both have moderate negative loadings from PC1, % sand and available water content have small negative and postive loadings respectively (Supplemental figure).  Tree density had significantly bimodal distributions between 0 and -5 scores of PC1, which corresponded to intermediate values of temperature and precipitation (530 - 900 mm/year and 2 - 10 degC). Based on this analysis, we estimate that up to 34% (212,032 km^2) of the the past landscape had a an environment where savanna and forests were bistable (figure 4).

  The historic bistablity of forests and savannas throughout a large region of the Midwest would predict strong senstivities to small changes in the environment. Rises in atmospheric CO2 have shifted mean climate since the end of the 20th century (add change in precip, temp), allowing us to test the hypothesis that small shifts in climate have driven the large changes observed in tree density (CITE density dist. figures, and difference figure). Projecting the historically bistable environmental space onto the modern landscape using modern climate, we estimate that if the historic climate-vegetation relationship had remained intact, and only climate had shifted, we would have expected 34.5% of the modern landscape to be bistable today (Figure 4). In sharp contrast to this, Modern tree denisty was not significantly bimodal overall, and climate space where bimodality occurs was detected on less than 1% of the landscape. While it is possible that climate may have shifted some previously bimodal savanna regions towards a closed forest alternative stable state (difference figure, FIA map), the majority of the modern landscape has shifted to stable closed forests, including places outside of the historically bistable region. Thus, the large scale stabilization of Midwestern forests is not likey due to shifts in climate, rather, land use change and disturbance regime shifts may have played a larger role than climate in the stabilization towards closed forests. 
  
  These findings have practical implications for the future resilience of the region because the transition of the modern landscape to closed forests constitutes a stability regime change shift that is may not be easily reversible. Using our new understanding of the the climate space where forests are bimodal (unstable) in the past, and now, we can make broad predictions for the future stability of midwestern forests. If the relationship between climate/soils and PLS vegetation held in the future, the climate changes projected under the RCP 2.6, RCP4.5, and RCP 8.5 emmissions scenarios (for CMIP5 CCESM4 climate projections) would result in some increases and spatial shifts in the instability of Midwestern forests (Figure 4a).  However, the current regime of fire suppression is likely to remain, and starting with a modern relationship between climate/soils and modern vegetaion, the climate changes projected under the RCP 2.6, RCP4.5, and RCP 8.5 emmissions scenarios (again for CCESM4 only) would likely result in stable closed forests in the Midwest maintaining, or increasing ecosystem stability (Figure 4b). 
  
  The implications of future projections of forest stability need to be evaluated in the context of the likely mechanisms underlying this stablization. Fire and disturbance-vegetation feedbacks are oft hypotheised mechansisms for alternative savanna and forest stable states and intermediate tree density (CITE Staver, tropics lit, Grimm 1984, Anderson). These hypothesized historic disturbances would maintain open understory, low tree density savannas by removing a large portion of seedlings and promoting understory grasses. These open places with high fuel loads would increase the likelihood of future burning, maintaining openness. However, low light availablity and wet microclimates in a closed forest may prevent understory fuel load from developing, resulting in a very low liklihood of fire spread into a closed forest. These bistable systems would have a stability compensation point or threshold of tree density where above it the vegetation feedbacks promote forest and below it the vegetation-disturbance feedbacks create open savanna ecosystems. The high frequency of savanna and closed forest density modes in the PLS dataset, with a much lower frequency intermediate density in the past that suggest an unstable point occurred at about  ~50 trees/hectare in the past, which incendentially corresponds to the savanna-forest breakpoint by some classifications (Anderson). The large shift and increase in intermediate tree density sites resulting in a largely stable closed forest on the modern landscape occurred concurrently with large scale fire suppression across the landscape, providing further support of fire/disturbances as important determinants of savanna and forest alternative attractors in the region (Nowacki et al 2008). Lack of large scale regional fire disturbance records from before European agricultural settlement prevents us from explicitly including fire frequency as a driver in this analysis. 

  While fire-disturbance feedbacks and fire suppression are reasonable candidate mechanisms for historic ecosystem bistability and stabilization towards closed forests on the modern landscape, other envrionmental changes in the region almost certainly played a role in stabilization.  Land use changes, particularly large scale agricultural conversion in the region converted many open grassland and savanna regions into crops (CITE), which are non-forested areas that were not included in this analysis. Forests logged in the early-20th century in the north are likely regenerating and result in an increase in tree density in historically forested areas (diff figure, rheumtella, goring, CITE others) We examine possible climate shifts that would have slightly increased the bistable climate space, potentially allowing more open regions to approach their tipping point/threshold. Increases in atmospheric CO2 that are driving observed climatic shifts could also have favored forest growth by enhancement of tree WUE and growth, or increasing sapling survival in savannas (CITE). 


Outline for the conclusions/interpretations:
  *other implications/ interpretations
    +land managment implications (required effort for restoring savannas may be high)
    +forest biodiveristy implications
    +consequences for understanding s-f transitions  & resilience globally
  
  
Other notes: 
  *Many of the interretations paragraphs as they stand are too wordy, and I am not sure they convey the points I want them too. 
  *Do the first two paragraphs provide enough context for the problem?
  *Is the problem statement clear? Does it lead directly into our approach or solution for the problem? 




## Figures:

### Figure 1:Public land survey tree density is bimodal and FIA tree density is not:

![](outputs/v1.6-5/FIA_PLS_hists.png) 
![](outputs/v1.6-5/tree_density_maps_PLS_FIA.png)
![](outputs/v1.6-5/PLS__full_tree_density_map.png)

### Figure 2: Change in tree density between the modern and historic vegetation depends on original vegetation density.
![](outputs/v1.6-5/density_difference_plot.png)

### Figure 3: 
Using the climate space with reduced dimensionality (PC1) and the vegetation classificaitons from rheumtella, we can map out places where tree density was bimodal in the past:

![](outputs/v1.6-5/full/PLS_PC1_PC2_map.png)

![](outputs/v1.6-5/FIA_PC1_PC2_map.png)
![](outputs/v1.6-5/MAP_deltaTEMP_bimodal_space.png)
![](outputs/v1.6-5/MAP_TEMP_bimodal_space.png)

### Figure 4a: Stability maps for pre-settlement vegetation-environment relationship with CCSM4 future climate (2070-2099)

![](outputs/v1.6-5/full/RCP_scenario_PC1_maps.png)

Also several places were no analog climates w.r.t. the PLS climate:
![](outputs/v1.6-5/full/RCP_scenario_PC1_noanalog_maps.png)

### Figure 4b: Stability maps for modern vegetation-environment relationship with CCSM4 future climate (2070-2099)
![](outputs/v1.6-5/RCP_scenario_PC1_maps_FIA.png)

Also several places were no analog climates w.r.t. the FIA climate:
![](outputs/v1.6-5/RCP_scenario_FIA_PC1_noanalog_maps.png)






  
Supplemental Material:   

*Generalized Additive Models/Relationship between historic vegetation and climate/soil variables*

Gam model selection for the model with the lowest AIC value yeilded the model: tree density ~ s(MAP) + s(mean annual temperatue) + s(deltaT) + s(deltaP) + s(sandpct) + s(awc). While AIC suggests this is the best model (Table 1), it only explains 61% of the Deviance and has high Mean squared prediction error for predicting the test data set (MSPE = 5976.366). Prediction of tree density is overestimated in low tree denisty grid cells and underestimated in high tree denisty grid cells.  

The Gam model for the modern landscape explained only 29 % of the deviance and had a high mean squared prediction error for predicting the test data set (MSPE = XXXX). Prediction of tree density is again overestimated in low tree denisty grid cells and underestimated in high tree density grid cells. 


##Methods:
*Public Land Survey Data:*
The Public Land Survey was commissioned by the U.S. General Land Office to assess the quality of land/timber and assign land titles for Euro-american settlers. The surveyors placed corner posts at 1 mile section corners in a grid within each township. At these section corners, and at 1/4 section corners, the surveyors would record the distance and azimuth from the corner to the nearest two trees, the species of the nearest two trees, and the diameter at breast height (DBH) of those trees. After these historic records were digitized (cite Mladenoff et al. ), we estimate the denisty and basal area at each corner point using the unbiased morista density estimator with correction factors for surveyor bias (@goring_2016, CITE Cogbill). Tree density is averaged across 8km x 8km grid cells in the upper Midwest.

*Forest Inventory Analysis Data:*

Add FIA data methods from Sean/Simon/Jack. FIA estimated tree denisty is also aggregated to the same 8km raster grid resolution.

*Climate Data*

  Mean annual temperature and Mean annual Precipitation data for the modern and historic vegetation-climate relationships are from PRISM datasets. Modern mean annual temperature and precipitation fore each 8km grid cell is calculated from the 800m 30-year Normals dataset. Historical climate is estimated as the average annual Temperature and average annual Precipiation over the 1895-1910 period. While this historical climate period does not overlap with the entirety of the European agricultural settlement era, this climatic period is the oldest for which we have reliable estimates of temperature and precipitation in the region. Precipitation seasonality was calculated from Monthly Prism datasets as follows: 

SI = sum 1-12(abs(mi - P/12))/P * 100

Temperature is calculated using the coefficient of variation method
TSI = sd(m1....m12)/Tavgannual *100
 
  
*Soil data*

  Soils data are derived from statewide gSSURGO 10m raster data product (<https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/home/?cid=NRCS142P2_053628>).  The weighted averages from the top 30cm of the soil were calculated for % sand, available water content (awc), and saturated hydraulic conductivity (ksat) soil parameters using the gSSURGO On-Demand ArcGIS toolbox (<https://github.com/ncss-tech/ssurgoOnDemand.git>). Weighted averages were calculated on the statewide soil raster datasets for Minnesota, Michigan, Wisconsin, Indiana, and Illinois, then weighted average rasters were mosaicked together to produce one single raster dataset. Maps of soil parameters were then aggregated to a 1km grid scale and an 8km Great Lakes St. Lawrence projected grid scale (PalEON dataset scale).

*Pricipal Component Analysis*

Since many climate and soils variables are often correlated, a pricipal components analysis was conducted to reduce dimensions and co-linearity in the environmental data. PCA was coducted on the scaled variables of historic MAP, historic Mean temperature, historic Precipitation Seasonality Index, Historic Tempearture Seasonality, AWC, and %sand. The modern principal component scores for climatic and soil variables were predicted using the historic principal component model. This method maintains the PCA of modern and historic environmental data on the same scale. The 1st Principal Component (PC1) was then used as a covariate when assessing bimodality. 

  
*Bimodality analysis*

Criteria for bimodality uses a both a bimodality coefficient (BC) and Hartigans Diptest for unimodality. Bimodality Coefficient is calculated from size, skewness, and kurtosis of the distributions (Pfister et al. 2013). A BC greater than 0.556 suggests bimodality. Bimodality coefficient (BC) is calculated from the distribuiton of data as follows using the R package 'modes':

BC = $\frac{(skew^2 + 1)}{(kurtosis + 3)*\frac{(n-1)^2}{(n-2)*(n-3)}}$

Desnity distributions of the PLS and FIA data were estimated. We then calculated the BC and performed Hartigan's diptest for unimodaltity for the on these smoothed density distribuitons for the PLS and FIA overall, and the BC within different bins of precipitation and the 1st Principal Component. Hartigan's diptest has a null hypothesis of a unimodal distribution of the data (CITE). This provides one BC value for a given range of precipitation/PC and whether the distribution is significantly different from a unimodal distribution. These ranges are used to determine the climate space where savannas and closed forests coexist.  

*Generalized Additive Models*

In addition to evaluating the BC for ranges of data, we developed several generalized additive models (GAMs) to determine if tree density can be deterministically predicted by climate and/or soils. GAMs were developed with both strictly additive terms and with flexible smooth terms. The full PLS data and FIA data were separated into two random halves that make up the testing and training datasets. GAM's were developed with the training dataset, and prediction error was estimated using the test dataset. Model parsimony was evaluated basing on AIC values, and model fit was assessed using RMSE. 

*Future Forest Stability under CMIP5 projected climate scenarios*

To investigate the consequences of the modern climate-vegetation relationship, and the past climate-vegetation relatiohsip would have for the stability of future midwestern forests, we utilized climate projections from CMIP5 representative concentration pathways (rcps) 2.6, 4.5, and 8.5. We obtained average monthly precipitation, total annual precipitation, average monthly temperature, and average annual temperature projections for 2070-2099 under the three RCP scenarios from the CCESM4 GCM climate downscaled climate projections (from worldclim, cite). We calculated precipitation and temperature seasonality as described above. Principal componenet scores (based on the past climate PCA) were assigned for each grid cell using the projected climate data from each RCP. 

We then identified the climate space (within PC1) that was bimodal in the PLS time, and mapped where this climate space is projected to be in 2070-2100. We also identified the climate space where FIA forests were bimodal on the modern landscape, and where this climate space would be in 2070-2100.



## Discussion:

  Tree density in the past was significantly bimodal, and was not accounted for by climate or soil factors, supporting our hypothesis that savannas and forests were alternative stable states in the region.  Projecting the past climate-vegeation relationship onto the modern climate would drive shifts in the climate space where bistable tree distributions are possible, but continue to predict large extent of savanna and forest alternative stable states on the modern landscape. However, modern tree density is no longer bimodal on the modern landscape, suggesting an unexpected shift towards stable closed forests in the region. Neither past tree density nor modern tree density has a fully deterministic relationship with climate, but bimodality in past tree density is predominant at intermediate temperature and precipitation space.  These largescale shifts from alternative savanna and forest stable states towards stable closed forests indicate that land use changes (fire suppression, logging, agricultural conversion) have had a far greater impact on midwestern woody ecosystems than changes in climate over the last ~150 years.  
  
  Land use changes that have led to fire suppression and land conversion in the region have long been hypothesized to drive "mesophication" (Nowacki and Abrams 2008), and increases in woody cover in the region. Additionally, small scale studies indicate that historic geography that would act as fire breaks (rivers and topography) are important explanatory variables for PLS vegetation (Grimm 1984). Modern land management strategies for restoring open savannas and grasslands in the region require extensive cutting and prescribed burns to limit understory tree growth (CITE). (CITE) suggest that a shift in overall fire return intervals have shifted southern midwest savanna and grasslands towards mesophytic forests and require larger and longer efforts of prescribed burns to return these ecosystems to their open states. While there has been small scale evidence that fire and disturbances were historically important for the maintence of temperate savanna-forest boundary in the US, our study is the first to document evidence for alternative savanna and forest stable states across a large region of the midwest. Additionally, the modern landscape after long term land use changes and post-settlement fire suppression has become mostly stable forests. 
  
  Evidence for alternative savanna and forest stable states in the temperate Midwest provides evidence that bistable systems are not constricted to the tropics. In the tropics, intermediate precipitation and high precipiation seasonality is the climatic domain for alternative stable states. However, our finding of temperate alternative stable states at much lower precipitaiton levels and temperatures, indicate that the constraints on growth identified in the tropics do not impose hard limits on the extent of these systems globally. Rather, we propose that alternative stable states are constrained to regions of intemediate moisture, where disturbance feedbacks occur. 

  Overall the shifts between the modern landscape and the pre-European settlement is marked by large scale forest stabilization, a shift from bimodal distribution in tree cover characterized by closed forests and open savannas, to mostly closed forested ecosystems. Throughtout the holocene, shifts in tree composition and tree cover have been linked to climatic variability across the region (CITE). However, this recent shift is not predicted by the observed changes in temperature, precipitation, or T/P seasonality. Rather, we propose that increased fire suppression and removal of disturbances from the landscape as likely mechanisms for overall shift towards closed forests. However, lack of direct evidence for the mechanism of these shifts makes it difficult to direct attribute the cause. Additonally, increases in atmospheric CO2 have been hypothesized to have a CO2 fertilization effect on tree growth, and could increase forest cover by increasing growth and tree recruitment (Wycoff and Bowers, CITE recruitment paper). To determine how much a CO2 fertilization effect may have contributed to increased forest cover in the Midwest, mechanistic evidence for CO2 fertilization in the region is needed. 
  
  The distribution of tree density across the region and the stabiliity of ecosystems to envrionmental changes can have large consequences for future biodiversity, carbon storage, and management decisions. Although evidence for alternative savanna and forest stable states in the midwest and throughout the globe suggest the potential for large scale forest/biome instability with changes in climate, ongoing land use changes and fires suppression have historically stabilized forests in the midwest. While increased stability of terrestrial ecosytems is a positive effects of the "mesophication" and overall conversion of savannas and grasslands to forests, it may come at the large cost of species biodiversity loss, increased vegetation homogenity, and loss of habitat. Assuming current land cover strategies continue, the modern forests are not likely to revert back to savanna in response of climate. However, increased likelihood of fire disturbances and further land use changes that may accompany changes in climate could alter the stability of the region. Being able to identify forest stability, and vegetation responses to different types of environmental changes will be important to understanding the trajectory of future forest and savanna biomes.  
  





# Supplemental Figures:
Additionally, the biplot for the Principal Components Analysis:
![](outputs/v1.6-5/full/pca_biplot.png)



# Climate space where the bimodality occurs: (3d plots):

![](outputs/3d_1.png)
![](outputs/3d_2.png)

We predict the binomial probability of having closed forest (tree density over 47 trees/hectare) given precipation, temperature, precip seasonality, temperature seasonality, % sand and awc. We get a decrease in probability of forests predicted in the open savanna regions, but the places with intermediate probability suggest unstable intermediates where savannas and forests are equally probable given the environmental data.


![](outputs/v1.6-5/full/logistic_pred_prob_testdata.png)

Here is the mapped distribution if we used the whole dataset (note this includes both training and testing dataests, I just wanted to look at a non-pixelated map)

![](outputs/v1.6-5/full/logistic_pred_prob_full.png)

# Tables with GAM model fits for PLS grid cells where we document unimodal distributions in tree cover:

# Issues with the GAM models: some models are predicting a few grid cells to be negative density (at the tails). Likely due to gaussian distn. family that was picked. The GLM models do not predict the negative density values, but still underestimate the low denisty places

Table 1: PLS density GAM models for stable sites
```{r, echo = FALSE, warning = FALSE}

suppressMessages(library(mgcv))
suppressMessages(library(caTools))
suppressMessages(library(ggplot2))
suppressMessages(library(MASS))

#dens.pr <- read.csv("data/midwest_pls_density_pr_alb1.6-5.csv") # just with grid cells that have both pls & FIA
#dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") # full set of PLS data
#hist(dens.pr$PLSdensity, breaks = 50)
#dens.pr <- read.csv("data/PLS_full_dens_pr_with_bins.csv")

dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/outputs/PLS_full_dens_pr_bins_with_bimodality_for_PC1.csv") 


pls.new <- dens.pr[dens.pr$bimodal == "Stable",] # remove all bimodal places for now
pls.bimodal <- dens.pr[dens.pr$bimodal == "Bimodal",]

pls.new <- pls.new[pls.new$PLSdensity > 0.5, ]# remove all zero places
dens.pr <- pls.new
dens.pr <- pls.new

# split into test and training datasets:
Y <- dens.pr$PLSdensity
msk <- sample.split( Y, SplitRatio = 1/4, group = NULL )
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]

#ggplot(dens.pr, aes(x = MAP1910, y = PLSdensity))+geom_point()
#ggplot(dens.pr, aes(x = MAP1910, y = pasttmean, color = PLSdensity))+geom_point()

# basic climate plots of data with only "stable forests/savannas"
PLS.gam1 <-gam(PLSdensity ~ MAP1910, data = train)
PLS.gam1L <-gam(PLSdensity ~  MAP1910, data = train)

pr <- predict(PLS.gam1L, test)
#summary(pr)
#plot(pr, test$PLSdensity)

PLS.gam2 <- gam(PLSdensity ~ s(pasttmean) , data = train)
PLS.gam2L <- gam(PLSdensity ~ pasttmean , data = train)
#summary(PLS.gam2) #explains 15.8% deviance
#plot(PLS.gam2)

PLS.gam3 <- gam(PLSdensity ~ s(pastdeltaP),data = train)
PLS.gam3L <- gam(PLSdensity ~ pastdeltaP,data = train)
#summary(PLS.gam3) #explains 6.07% deviance

PLS.gam4 <- gam(PLSdensity ~ s(deltaT), data = train)
PLS.gam4L <- gam(PLSdensity ~ deltaT, data = train)
#summary(PLS.gam4) #explains 6.07% deviance

PLS.gam5 <- gam(PLSdensity ~ s(awc),data = train)
PLS.gam5L <- gam(PLSdensity ~ awc, data = train)
#summary(PLS.gam5) #explains 12.5% of deviance

PLS.gam6 <- gam(PLSdensity ~ s(sandpct), data = train)
PLS.gam6L <- gam(PLSdensity ~ sandpct, data = train)
#summary(PLS.gam6) #explains 12.5% of deviance



PLS.gam7 <- gam(PLSdensity ~ s(pasttmean) + s(MAP1910) , data = train)
PLS.gam7L <- gam(PLSdensity ~ pasttmean + MAP1910 ,  data = train)
#summary(PLS.gam7) #explains 41% deviance


PLS.gam8 <- gam(PLSdensity ~ s(awc) +s(sandpct), data = train )
PLS.gam8L <- gam(PLSdensity ~ awc + sandpct, data = train )
#summary(PLS.gam8) #explains 28% of deviance

PLS.gam9 <- gam(PLSdensity ~ s(MAP1910) + s(pasttmean) + s(sandpct), data = train)
PLS.gam9L <- gam(PLSdensity ~ MAP1910 + pasttmean + sandpct, data = train)
#summary(PLS.gam9) #explains 39% deviance
#summary(PLS.gam9L)
#plot(PLS.gam6)


PLS.gam10 <- gam(PLSdensity ~ s(MAP1910) +s(pasttmean) + s(awc), data = train)
PLS.gam10L <- gam(PLSdensity ~ MAP1910 + pasttmean + awc, data = train)

#summary(PLS.gam10) #explains 41.3% of deviance
#plot(PLS.gam10)

PLS.gam11 <- gam(PLSdensity ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), data = train)
PLS.gam11L <- gam(PLSdensity ~ MAP1910  + pasttmean + sandpct + awc, data = train)

#summary(PLS.gam8) # explains 41% of deviance
PLS.gam12 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam12L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT, data = train)

PLS.gam14 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct), data = train)
PLS.gam14L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT + pastdeltaP + sandpct, data = train)

PLS.gam15 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), data = train, family = gaussian(link = 'identity'))
PLS.gam15L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT + pastdeltaP +sandpct + awc, data = train)

t <- predict(PLS.gam15, test[,c("PLSdensity", "MAP1910", "pasttmean", "deltaT", 'pastdeltaP', 'sandpct', 'awc')])
summary(t)

plot(t, test$PLSdensity)
abline (a = 0, b = 1, col = 'red')
hist(t)
hist(test$PLSdensity)

PLS.gam16 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP), data = train)
PLS.gam16L <- gam(PLSdensity ~ MAP1910  + pasttmean + deltaT + pastdeltaP, data = train)

AIC.df<- AIC(PLS.gam1, PLS.gam2, PLS.gam3, PLS.gam4, PLS.gam5, PLS.gam6, PLS.gam7, PLS.gam8, PLS.gam9,PLS.gam10,PLS.gam11,PLS.gam12,PLS.gam13,PLS.gam14 ,PLS.gam15,PLS.gam16, PLS.gam1L, PLS.gam2L, PLS.gam3L, PLS.gam4L, PLS.gam5L, PLS.gam6L, PLS.gam7L, PLS.gam8L, PLS.gam9L, PLS.gam10L,PLS.gam11L,PLS.gam12L,PLS.gam13L,PLS.gam14L,PLS.gam15L, PLS.gam16L)

#AIC.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC.df$formula <- c(PLS.gam1$formula, PLS.gam2$formula, PLS.gam3$formula, PLS.gam4$formula, PLS.gam5$formula, PLS.gam6$formula, PLS.gam7$formula, PLS.gam8$formula, PLS.gam9$formula,PLS.gam10$formula,PLS.gam11$formula,PLS.gam12$formula,PLS.gam13$formula,PLS.gam14$formula ,PLS.gam15$formula ,PLS.gam16$formula , PLS.gam1L$formula, PLS.gam2L$formula, PLS.gam3L$formula, PLS.gam4L$formula, PLS.gam5L$formula, PLS.gam6L$formula, PLS.gam7L$formula, PLS.gam8L$formula, PLS.gam9L$formula, PLS.gam10L$formula,PLS.gam11L$formula,PLS.gam12L$formula,PLS.gam13L$formula, PLS.gam14L$formula, PLS.gam15L$formula,PLS.gam16L$formula)

AIC.df<- AIC.df[order(AIC.df$AIC),]
library(knitr)
library(pander)
AIC.df$model <- rownames(AIC.df)

#calculate prediction error:
msqe<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$PLSdensity - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC.df$dev.expl <- 1

#add prediction error & Deviance Explained to the AIC dataframe

for (i in 1: length(AIC.df$model)){
AIC.df[i,'MSPE'] <- msqe(get(AIC.df[i,"model"]), test)
AIC.df[i,"dev.expl"] <- summary(get(AIC.df[i,"model"]))$dev.expl * 100
}

#pander(AIC.df[,c("model", "formula", "df", "AIC", "MSPE", "dev.expl")], split.cells = 30)

print(AIC.df)

```



Table 2: FIA density GAM models
```{r, echo = FALSE, warning = FALSE}

suppressMessages(library(mgcv))
suppressMessages(library(caTools))
suppressMessages(library(ggplot2))

#dens.pr <- read.csv("data/midwest_pls_density_pr_alb1.6-5.csv") # just with grid cells that have both pls & FIA
#dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") # full set of PLS data
#hist(dens.pr$PLSdensity, breaks = 50)
#dens.pr <- read.csv("data/PLS_full_dens_pr_with_bins.csv")

fiadens <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/dens_pr_PLS_FIA_with_cov.csv")

fiadens <- fiadens[fiadens$FIAdensity > 47, ]
#split FIA data into test and trainfing datasets
Y <- fiadens$FIAdensity
msk <- sample.split( Y, SplitRatio = 1/4, group = fiadens$fiaecotype )
#table(Y,msk)

trainf <- fiadens[msk,]
testf <- fiadens[!msk,]


FIA.gam1 <-gam(FIAdensity ~  s(MAP2011), data = trainf)
FIA.gam1L <-gam(FIAdensity ~  MAP2011, data = trainf)


FIA.gam2 <- gam(FIAdensity ~ s(modtmean) , data = trainf)
FIA.gam2L <- gam(FIAdensity ~ modtmean , data = trainf)
#summary(FIA.gam2) #explains 5.6% deviance
#plot(FIA.gam2)

FIA.gam3 <- gam(FIAdensity ~ s(moderndeltaP), data = trainf)
FIA.gam3L <- gam(FIAdensity ~ moderndeltaP, data = trainf)
#summary(FIA.gam3) #explains 6.07% deviance

FIA.gam4 <- gam(FIAdensity ~ s(moddeltaT), data = trainf)
FIA.gam4L <- gam(FIAdensity ~ moddeltaT, data = trainf)
#summary(FIA.gam4) #explains 6.07% deviance

FIA.gam5 <- gam(FIAdensity ~ s(awc),data = trainf)
FIA.gam5L <- gam(FIAdensity ~ awc, data = trainf)
#summary(FIA.gam5) #explains 12.5% of deviance

FIA.gam6 <- gam(FIAdensity ~ s(sandpct), data = trainf)
FIA.gam6L <- gam(FIAdensity ~ sandpct, data = trainf)
#summary(FIA.gam6) #explains 12.5% of deviance



FIA.gam7 <- gam(FIAdensity ~ s(modtmean) + s(MAP2011) , data = trainf, family = quasipoisson())
FIA.gam7L <- gam(FIAdensity ~ modtmean + MAP2011 ,  data = trainf)
#summary(FIA.gam7) #explains 41% deviance
#summary(FIA.gam7L) # explains 19.6%

FIA.gam8 <- gam(FIAdensity ~ s(awc) +s(sandpct), data = trainf )
FIA.gam8L <- gam(FIAdensity ~ awc + sandpct, data = trainf )
#summary(FIA.gam8) #explains 28% of deviance

FIA.gam9 <- gam(FIAdensity ~ s(MAP2011) + s(modtmean) + s(sandpct), data = trainf)
FIA.gam9L <- gam(FIAdensity ~ MAP2011 + modtmean + sandpct, data = trainf)
#summary(FIA.gam9) #explains 39% deviance
#summary(FIA.gam9L)
#plot(FIA.gam6)


FIA.gam10 <- gam(FIAdensity ~ s(MAP2011) +s(modtmean) + s(awc), data = trainf)
FIA.gam10L <- gam(FIAdensity ~ MAP2011 + modtmean + awc, data = trainf)

#summary(FIA.gam10) #explains 41.3% of deviance
#plot(FIA.gam10)

FIA.gam11 <- gam(FIAdensity ~ s(MAP2011)  +s(modtmean) +s(sandpct) + s(awc), data = trainf)
FIA.gam11L <- gam(FIAdensity ~ MAP2011  + modtmean + sandpct + awc, data = trainf)

#summary(FIA.gam8) # explains 41% of deviance
FIA.gam12 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moderndeltaP), data = trainf)
FIA.gam12L <- gam(FIAdensity ~ MAP2011  + modtmean + moderndeltaP, data = trainf)

FIA.gam13 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moderndeltaP), data = trainf)
FIA.gam13L <- gam(FIAdensity ~ MAP2011  + modtmean + moderndeltaP, data = trainf)

FIA.gam13 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT), data = trainf)
FIA.gam13L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT, data = trainf)

FIA.gam14 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT) + s(moderndeltaP)+s(sandpct), data = trainf)
FIA.gam14L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT + moderndeltaP, data = trainf)

FIA.gam15 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT) + s(moderndeltaP)+s(sandpct)+s(awc), data = trainf)
FIA.gam15L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT + moderndeltaP, data = trainf)

FIA.gam16 <- gam(FIAdensity ~ s(MAP2011)  + s(modtmean) + s(moddeltaT) + s(moderndeltaP), data = trainf)
FIA.gam16L <- gam(FIAdensity ~ MAP2011  + modtmean + moddeltaT + moderndeltaP, data = trainf)

AICf.df<- AIC(FIA.gam1, FIA.gam2, FIA.gam3, FIA.gam4, FIA.gam5, FIA.gam6, FIA.gam7, FIA.gam8, FIA.gam9,FIA.gam10,FIA.gam11,FIA.gam12,FIA.gam13,FIA.gam14 ,FIA.gam15,FIA.gam16, FIA.gam1L, FIA.gam2L, FIA.gam3L, FIA.gam4L, FIA.gam5L, FIA.gam6L, FIA.gam7L, FIA.gam8L, FIA.gam9L, FIA.gam10L,FIA.gam11L,FIA.gam12L,FIA.gam13L,FIA.gam14L,FIA.gam15L, FIA.gam16L)

#AIC.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AICf.df$formula <- c(FIA.gam1$formula, FIA.gam2$formula, FIA.gam3$formula, FIA.gam4$formula, FIA.gam5$formula, FIA.gam6$formula, FIA.gam7$formula, FIA.gam8$formula, FIA.gam9$formula,FIA.gam10$formula,FIA.gam11$formula,FIA.gam12$formula,FIA.gam13$formula,FIA.gam14$formula ,FIA.gam15$formula , FIA.gam16L$formula, FIA.gam1L$formula, FIA.gam2L$formula, FIA.gam3L$formula, FIA.gam4L$formula, FIA.gam5L$formula, FIA.gam6L$formula, FIA.gam7L$formula, FIA.gam8L$formula, FIA.gam9L$formula, FIA.gam10L$formula,FIA.gam11L$formula,FIA.gam12L$formula,FIA.gam13L$formula, FIA.gam14L$formula, FIA.gam15L$formula, FIA.gam16L$formula )

AICf.df<- AICf.df[order(AICf.df$AIC),]
library(knitr)
library(pander)
AICf.df$model <- as.character(rownames(AICf.df))

#calculate prediction error:
msqe.f<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$FIAdensity - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AICf.df$MSPE <- 1
AICf.df$dev.expl <- 1

#add prediction error of AIC dataframe

for (i in 1: length(AICf.df$model)){
AICf.df[i,'MSPE'] <- msqe.f(get(AICf.df[i,"model"]), testf)
AICf.df[i,"dev.expl"] <- summary(get(AICf.df[i,"model"]))$dev.expl * 100
}

print(AICf.df)
#print(AICf.df[,c("model", "formula", "df", "AIC", "MSPE")], split.cells = 30)

```


###Predicting Tree density (GAMs)

The model with the lowest AIC value is represented by the formula:
PLSdensity ~ s(MAP) + s(MAT) + s(TempCV) + s(PrecipSI) + s(% sand) + s(awc)

Addtionally, for the FIA dataset the model with the lowest AIC also includes MAP, MAT, TempCV, PrecipSI, % sand, and awc. However, the model fits for the modern landscape are substantially lower.

# Supplemental PLS density model fit figures:
```{r, echo = FALSE, warning = FALSE}
suppressMessages(library(maps))
suppressMessages(library(sp))
suppressMessages(library(rgeos))
suppressMessages(library(visreg))
all_states <- map_data("state")
states <- subset(all_states, region %in% c(  'minnesota','wisconsin','michigan',"illinois",  'indiana') )
coordinates(states)<-~long+lat
class(states)
proj4string(states) <-CRS("+proj=longlat +datum=NAD83")
mapdata<-spTransform(states, CRS('+init=epsg:3175'))
mapdata <- data.frame(mapdata)
cbpalette <- c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837")
#map out 


# plot the predicted response fields to these variables
# make a function to extracted predictions from a model
get.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")

testdata$ypred <- ypred

testdata
}

# for the PLS:
predicted <- get.preds(PLS.gam16, test)
#summary(predicted$ypred)

# for the PLS bimodal only places
predictedbm <- get.preds(PLS.gam16, pls.bimodal)

#summary(predictedbm$ypred)


msqe<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$PLSdensity - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

msqe(PLS.gam15L, test)
msqe(PLS.gam15L, pls.bimodal)



# predictions for FIA
predictedf <- get.preds(FIA.gam15, testf)
summary(predictedf$ypred)


####################################
# Plotting predicted vs. observed ##
####################################

# Define function to plot predicted vs. observed:
pvsobs <- function(preds, obs, colorby, model ){
# plot predicted vs. observed for PLS
ggplot(preds, aes(preds[,obs], ypred, color = preds[,colorby])) +geom_point() + theme_bw()+geom_abline(intercept = 0, slope = 1, color = 'red', size = 2) + #ylim (-10, 600)+xlim(-10,600) +
  ggtitle(paste('Predicted vs. Observed', model)) + ylab('Predicted tree density') + xlab('Observed tree density')
}

# plot predicted vs. observed for PLS model 15
pvsobs(preds = predicted, obs = 'PLSdensity', colorby = "PC1", model = "PLS density")

# plot predicted vs. observed for PLS model 15
pvsobs(preds = predictedbm, obs = 'PLSdensity', colorby = "PC1", model = "PLS density Bimodal only places")


# plot FIA predicted vs. observed model 15
pvsobs(preds = predictedf, obs = 'FIAdensity', colorby = "PC1", model = "FIA density")


```
The predicted vs. observed plot shows overestimation of PLS tree density in Low density areas and underestimation of PLS tree density in High density areas. Below we map out the predictions and prediction errors in space. Model fit has improved for the stable portions of the PLS landscape, and does an Okay job predicting PLS tree density. Note that the predictions here are overall much higher than the observations for FIA tree denisty. 


 # Map out predictions in space:
```{r, echo = FALSE, warning = FALSE}

# Creat a function to plot the predicted tree denisty in the map
map.preds <- function(preds, model){
ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=preds, aes(x=x, y=y, fill = ypred))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title=paste("Predicted", model)) + 
  scale_fill_gradientn(colours = c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837"), limits = c(0,700), name ="Tree \n Density \n (trees/hectare)", na.value = 'darkgrey') +
  coord_equal()+theme_bw()
  
}

map.preds(preds = predicted, model = "PLS denisty")
map.preds(preds = predictedbm, model = "PLS denisty bimodal only")

map.preds(preds = predictedf, model = "FIA denisty")


```

#Mapping out predicted - observed for each grid cell in the test dataset. 

```{r, echo = FALSE,  warning = FALSE}

suppressMessages(library(RColorBrewer))

# function to calculate discrete bins of model error
diserror.map<- function (preds, obs, model){
# calculate preds - observed
preds$podiff <- preds[,'ypred'] - preds[,obs]

Sd = rep(0,length(preds$podiff))
  Sd[which(preds$podiff>0 & preds$podiff<=10)] = 1
  Sd[which(preds$podiff>10 & preds$podiff<=50)] = 2
  
  Sd[which(preds$podiff>50 & preds$podiff<=100)] = 3
  Sd[which(preds$podiff>100) ] = 4
  Sd[which(preds$podiff== 0)] = 0
   Sd[which(preds$podiff>=-10 & preds$podiff<0)] = -1
  Sd[which(preds$podiff>-50 & preds$podiff<=-10)] = -2
  
  Sd[which(preds$podiff> -100 & preds$podiff<=-50)] = -3
  Sd[which(preds$podiff< -100) ] = -4
  Sd = factor(Sd,levels=-4:4)
  levels(Sd) = c(">-100","(-100,-50]","(-50, -10]","(-10,0]",'0','(0,10]','(10,50]','(50, 100]','(100,200]')
  
  preds$errordiscrete <- Sd
  
 gs.pal <- colorRampPalette(brewer.pal(11,"PRGn"))


# map out preds - observed using discrete scale
ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=preds, aes(x=x, y=y, fill = errordiscrete))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title=paste("Predicted - Obs", model)) +scale_fill_manual(values=gs.pal(9),drop=FALSE) +
  coord_equal()+theme_bw()
}

diserror.map ( preds = predicted, obs = "PLSdensity", model = "PLS density")

diserror.map ( preds = predictedbm, obs = "PLSdensity", model = "PLS bimodal places")


diserror.map ( preds = predictedf, obs = "FIAdensity", model = "FIA density")


```



# Plot the predicted - observed by veg class
```{r, echo = FALSE,  warning = FALSE}
suppressMessages(library(modes))
suppressMessages(library(gridExtra))

class.plots<- function(preds, obs, class){
preds$podiff <- preds[,'ypred'] - preds[,obs]

a <- ggplot(preds, aes(x = preds[,class], y = podiff))+geom_boxplot()+xlab("Predicted - Observed for different Bimodal regions")+theme_bw()

b <- ggplot(preds, aes(x = podiff)) + geom_vline( aes(xintercept=0), colour="red") +geom_histogram()+facet_grid(preds[,class]~., scales = 'free') + xlab("Predicted - Observed for different Bimodal regions") + theme_bw()
grid.arrange(a,b, ncol = 1, nrow = 2)
}

class.plots(preds = predicted, obs = "PLSdensity", class = 'classification')
class.plots(preds = predictedbm, obs = "PLSdensity", class = 'classification')

class.plots(preds = predictedf, obs = "FIAdensity", class = 'fiaecotype')


```

# Plot predicted - obs against density:

```{r, echo = FALSE,  warning = FALSE}

plot.po.dens <- function(preds, obs, model){
preds$podiff <- preds[,'ypred'] - preds[,obs]
Sd = rep(0,length(preds$podiff))
  Sd[which(preds$podiff>0 & preds$podiff<=10)] = 1
  Sd[which(preds$podiff>10 & preds$podiff<=50)] = 2
  
  Sd[which(preds$podiff>50 & preds$podiff<=100)] = 3
  Sd[which(preds$podiff>100) ] = 4
  Sd[which(preds$podiff== 0)] = 0
   Sd[which(preds$podiff>=-10 & preds$podiff<0)] = -1
  Sd[which(preds$podiff>-50 & preds$podiff<=-10)] = -2
  
  Sd[which(preds$podiff> -100 & preds$podiff<=-50)] = -3
  Sd[which(preds$podiff< -100) ] = -4
  Sd = factor(Sd,levels=-4:4)
  levels(Sd) = c(">-100","(-100,-50]","(-50, -10]","(-10,0]",'0','(0,10]','(10,50]','(50, 100]','(100,200]')
  
  preds$errordiscrete <- Sd
  
 gs.pal <- colorRampPalette(brewer.pal(11,"PRGn"))

ggplot() + geom_point(data = preds, aes(x= preds[,obs], y = podiff, color = errordiscrete)) +scale_color_manual(values=gs.pal(9),name = "Pred-Obs",drop=FALSE)+ theme_bw() + xlab("Tree density")+ ylab("Predicted - Observed") + ggtitle(paste("Predicted - obs. vs.", model))
}

plot.po.dens(predicted, "PLSdensity", model = "PLS density")
plot.po.dens(predictedbm, "PLSdensity", model = "PLS density bimodal cells")

plot.po.dens(predictedf, "FIAdensity", model = "FIA density")

```
PLS model trained on the stable places results in high overpredictions for low tree denisty areas and moderate underprediction for tree density in high density grid cells. 

FIA models overpredict over the places that have low tree denisty. I think that if we remove the low denisty places, we might be able to better predict. 


## Predicting Forest vs. Savanna (not density)

The above models are predicting density (continious variable) from continous envrionmental and climate covariates. However, we can also use the savanna/forest density classificaitons as our y variable and  predict the probability a grid cell is forest (ecocode = 1, PLS density > 47 trees/ha) and savannna (ecocode = 0, PLSdensity < 47 trees/ha & >0.5 trees/ha) from continous environmental and climate covariates. 


This method has the benefit of predicting the probability of forest (or the probability of savanna) given certain environmental conditions. For this analysis, we exclude prairie sites

# Modeling p(forest):
```{r echo = FALSE, warning = FALSE}
dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") 

# dummyvariables for logistic regression:
dens.pr$ecocode <- 0
dens.pr[dens.pr$ecotype %in% 'Forest', ]$ecocode <- 1
dens.pr<- dens.pr[!dens.pr$ecotype %in% 'prairie',]

#split trainfing and testing
Y <- dens.pr$ecotype
msk <- sample.split( Y, SplitRatio = 3/4, group = NULL)
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]


#plot(dens.pr$sandpct, dens.pr$ecotype)


PLS.lgr1 <-gam(ecocode ~  s(MAP1910), family = 'binomial',data = train)
PLS.lgr1L <-gam(ecocode ~  MAP1910, family = 'binomial',data = train)


PLS.lgr2 <- gam(ecocode ~ s(pasttmean) , family = 'binomial',data = train)
PLS.lgr2L <- gam(ecocode ~ pasttmean , family = 'binomial',data = train)
#summary(PLS.lgr2) #explains 15.8% deviance
#plot(PLS.lgr2)

PLS.lgr3 <- gam(ecocode ~ s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr3L <- gam(ecocode ~ pastdeltaP, family = 'binomial',data = train)
#summary(PLS.lgr3) #explains 6.07% deviance

PLS.lgr4 <- gam(ecocode ~ s(deltaT), family = 'binomial',data = train)
PLS.lgr4L <- gam(ecocode ~ deltaT, family = 'binomial',data = train)
#summary(PLS.lgr4) #explains 6.07% deviance

PLS.lgr5 <- gam(ecocode ~ s(awc), family = 'binomial',data = train)
PLS.lgr5L <- gam(ecocode ~ awc, family = 'binomial',data = train)
#summary(PLS.lgr5) #explains 12.5% of deviance

PLS.lgr6 <- gam(ecocode ~ s(sandpct), family = 'binomial',data = train)
PLS.lgr6L <- gam(ecocode ~ sandpct, family = 'binomial',data = train)
#summary(PLS.lgr6) #explains 12.5% of deviance



PLS.lgr7 <- gam(ecocode ~ s(pasttmean) + s(MAP1910) ,  family = 'binomial',data = train)
PLS.lgr7L <- gam(ecocode ~ pasttmean + MAP1910 ,  family = 'binomial',data = train)
#summary(PLS.lgr7) #explains 41% deviance
#summary(PLS.lgr7L) # explains 19.6%

PLS.lgr8 <- gam(ecocode ~ s(awc) +s(sandpct), family = 'binomial',data = train )
PLS.lgr8L <- gam(ecocode ~ awc + sandpct, family = 'binomial',data = train )
#summary(PLS.lgr8) #explains 28% of deviance

PLS.lgr9 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = 'binomial',data = train)
PLS.lgr9L <- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = 'binomial',data = train)
#summary(PLS.lgr9) #explains 39% deviance
#summary(PLS.lgr9L)
#plot(PLS.lgr6)


PLS.lgr10 <- gam(ecocode ~ s(MAP1910) +s(pasttmean) + s(awc), family = 'binomial',data = train)
PLS.lgr10L <- gam(ecocode ~ MAP1910 + pasttmean + awc, family = 'binomial',data = train)

#summary(PLS.lgr10) #explains 41.3% of deviance
#plot(PLS.lgr10)

PLS.lgr11 <- gam(ecocode ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), family = 'binomial',data = train)
PLS.lgr11L <- gam(ecocode ~ MAP1910  + pasttmean + sandpct + awc, family = 'binomial',data = train)

#summary(PLS.lgr8) # explains 41% of deviance
PLS.lgr12 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP),family = 'binomial', data = train)
PLS.lgr12L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

#PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT), family = 'binomial',data = train)
#PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT, family = 'binomial',data = train)

PLS.lgr14 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), family = 'binomial',data = train)
PLS.lgr14L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT + pastdeltaP, family = 'binomial',data = train)

AIC2.df<- AIC(PLS.lgr1, PLS.lgr2, PLS.lgr3, PLS.lgr4, PLS.lgr5, PLS.lgr6, PLS.lgr7, PLS.lgr8, PLS.lgr9,PLS.lgr10,PLS.lgr11,PLS.lgr12,PLS.lgr13,PLS.lgr14 , PLS.lgr1L, PLS.lgr2L, PLS.lgr3L, PLS.lgr4L, PLS.lgr5L, PLS.lgr6L, PLS.lgr7L, PLS.lgr8L, PLS.lgr9L, PLS.lgr10L,PLS.lgr11L,PLS.lgr12L,PLS.lgr13L,PLS.lgr14L)




AIC2.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC2.df$formula <- c(PLS.lgr1$formula, PLS.lgr2$formula, PLS.lgr3$formula, PLS.lgr4$formula, PLS.lgr5$formula, PLS.lgr6$formula, PLS.lgr7$formula, PLS.lgr8$formula, PLS.lgr9$formula,PLS.lgr10$formula,PLS.lgr11$formula,PLS.lgr12$formula,PLS.lgr13$formula,PLS.lgr14$formula , PLS.lgr1L$formula, PLS.lgr2L$formula, PLS.lgr3L$formula, PLS.lgr4L$formula, PLS.lgr5L$formula, PLS.lgr6L$formula, PLS.lgr7L$formula, PLS.lgr8L$formula, PLS.lgr9L$formula, PLS.lgr10L$formula,PLS.lgr11L$formula,PLS.lgr12L$formula,PLS.lgr13L$formula, PLS.lgr14L$formula )

AIC2.df<- AIC2.df[order(AIC2.df$AIC),]
library(knitr)
library(pander)
AIC2.df$model <- rownames(AIC2.df)

#calculate prediction error:
msqe.code<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$ecocode - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC2.df$MSPE <- 1

#add prediction error ot AIC dataframe

for (i in 1: length(AIC2.df$model)){
AIC2.df[i,'MSPE'] <- msqe.code(get(AIC2.df[i,"model"]), test)
}
pander(AIC2.df[,c("model","modeltype", "formula", "df", "AIC", "MSPE")], split.cells = 30)


#full <- dens.pr
full <- test
logsample <- predict(PLS.lgr14, full, type="response")
full$ypred <- as.numeric(logsample)
#summary(logsample)
#hist(test$ypred)

#ggplot(full, aes(x, y, color = ypred)) + geom_point()
#ggplot(test, aes(x, y, color = ecocode)) + geom_point()+coord_equal()

#ggplot(test, aes(ypred, PLSdensity))+geom_point()

#ggplot(test, aes (ypred, MAP1910))+geom_point()



# create discrete probability cuts
label.breaks <- function(beg, end, splitby){
  labels.test <- data.frame(first = seq(beg, end, by = splitby), second = seq((beg + splitby), (end + splitby), by = splitby))
  labels.test <- paste (labels.test$first, '-' , labels.test$second)
  labels.test
}


full$ypreddiscrete <- cut(full$ypred, breaks = seq(0,1, by = 0.2), labels = label.breaks(0,0.8, 0.2))



cbpalette <- c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837")

full$ypreddiscrete <- as.character(full$ypreddiscrete)
#ggplot(full, aes(x, y, color = ypreddiscrete)) + geom_point()



# plot the discrete probability of forest 
p.forest <- ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=full, aes(x=x, y=y, fill = ypreddiscrete))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="Climate Predicted Prob(forest)")+ scale_fill_manual(values= cbpalette) +
  coord_equal()+theme_bw()+ theme()

# plot PLS forests
pls <- ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=full, aes(x=x, y=y, fill = ecotype))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="PLS classification")+ scale_fill_manual(values= c("#006837", "#c2e699"))+ coord_equal()+theme_bw()

png(width = 8, height = 4, units = 'in', res = 300, filename = 'outputs/v1.6-5/full/logistic_pred_prob_testdata.png')
grid.arrange(pls, p.forest, nrow = 1, ncol=2)
dev.off()

```

# modeling p(savanna)
```{r echo = FALSE, warning = FALSE}
dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") 

# dummyvariables for logistic regression:
dens.pr$ecocode <- 1
dens.pr[dens.pr$ecotype %in% 'Forest', ]$ecocode <- 0
dens.pr<- dens.pr[!dens.pr$ecotype %in% 'prairie',]

#split trainfing and testing
Y <- dens.pr$ecotype
msk <- sample.split( Y, SplitRatio = 3/4, group = NULL)
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]


#plot(dens.pr$sandpct, dens.pr$ecotype)


PLS.lgr1 <-gam(ecocode ~  s(MAP1910), family = 'binomial',data = train)
PLS.lgr1L <-gam(ecocode ~  MAP1910, family = 'binomial',data = train)


PLS.lgr2 <- gam(ecocode ~ s(pasttmean) , family = 'binomial',data = train)
PLS.lgr2L <- gam(ecocode ~ pasttmean , family = 'binomial',data = train)
#summary(PLS.lgr2) #explains 15.8% deviance
#plot(PLS.lgr2)

PLS.lgr3 <- gam(ecocode ~ s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr3L <- gam(ecocode ~ pastdeltaP, family = 'binomial',data = train)
#summary(PLS.lgr3) #explains 6.07% deviance

PLS.lgr4 <- gam(ecocode ~ s(deltaT), family = 'binomial',data = train)
PLS.lgr4L <- gam(ecocode ~ deltaT, family = 'binomial',data = train)
#summary(PLS.lgr4) #explains 6.07% deviance

PLS.lgr5 <- gam(ecocode ~ s(awc), family = 'binomial',data = train)
PLS.lgr5L <- gam(ecocode ~ awc, family = 'binomial',data = train)
#summary(PLS.lgr5) #explains 12.5% of deviance

PLS.lgr6 <- gam(ecocode ~ s(sandpct), family = 'binomial',data = train)
PLS.lgr6L <- gam(ecocode ~ sandpct, family = 'binomial',data = train)
#summary(PLS.lgr6) #explains 12.5% of deviance



PLS.lgr7 <- gam(ecocode ~ s(pasttmean) + s(MAP1910) ,  family = 'binomial',data = train)
PLS.lgr7L <- gam(ecocode ~ pasttmean + MAP1910 ,  family = 'binomial',data = train)
#summary(PLS.lgr7) #explains 41% deviance
#summary(PLS.lgr7L) # explains 19.6%

PLS.lgr8 <- gam(ecocode ~ s(awc) +s(sandpct), family = 'binomial',data = train )
PLS.lgr8L <- gam(ecocode ~ awc + sandpct, family = 'binomial',data = train )
#summary(PLS.lgr8) #explains 28% of deviance

PLS.lgr9 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = 'binomial',data = train)
PLS.lgr9L <- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = 'binomial',data = train)
#summary(PLS.lgr9) #explains 39% deviance
#summary(PLS.lgr9L)
#plot(PLS.lgr6)


PLS.lgr10 <- gam(ecocode ~ s(MAP1910) +s(pasttmean) + s(awc), family = 'binomial',data = train)
PLS.lgr10L <- gam(ecocode ~ MAP1910 + pasttmean + awc, family = 'binomial',data = train)

#summary(PLS.lgr10) #explains 41.3% of deviance
#plot(PLS.lgr10)

PLS.lgr11 <- gam(ecocode ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), family = 'binomial',data = train)
PLS.lgr11L <- gam(ecocode ~ MAP1910  + pasttmean + sandpct + awc, family = 'binomial',data = train)

#summary(PLS.lgr8) # explains 41% of deviance
PLS.lgr12 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP),family = 'binomial', data = train)
PLS.lgr12L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), family = 'binomial',data = train)
PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = train)

#PLS.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT), family = 'binomial',data = train)
#PLS.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT, family = 'binomial',data = train)

PLS.lgr14 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), family = 'binomial',data = train)
PLS.lgr14L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT + pastdeltaP, family = 'binomial',data = train)

AIC2.df<- AIC(PLS.lgr1, PLS.lgr2, PLS.lgr3, PLS.lgr4, PLS.lgr5, PLS.lgr6, PLS.lgr7, PLS.lgr8, PLS.lgr9,PLS.lgr10,PLS.lgr11,PLS.lgr12,PLS.lgr13,PLS.lgr14 , PLS.lgr1L, PLS.lgr2L, PLS.lgr3L, PLS.lgr4L, PLS.lgr5L, PLS.lgr6L, PLS.lgr7L, PLS.lgr8L, PLS.lgr9L, PLS.lgr10L,PLS.lgr11L,PLS.lgr12L,PLS.lgr13L,PLS.lgr14L)




AIC2.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC2.df$formula <- c(PLS.lgr1$formula, PLS.lgr2$formula, PLS.lgr3$formula, PLS.lgr4$formula, PLS.lgr5$formula, PLS.lgr6$formula, PLS.lgr7$formula, PLS.lgr8$formula, PLS.lgr9$formula,PLS.lgr10$formula,PLS.lgr11$formula,PLS.lgr12$formula,PLS.lgr13$formula,PLS.lgr14$formula , PLS.lgr1L$formula, PLS.lgr2L$formula, PLS.lgr3L$formula, PLS.lgr4L$formula, PLS.lgr5L$formula, PLS.lgr6L$formula, PLS.lgr7L$formula, PLS.lgr8L$formula, PLS.lgr9L$formula, PLS.lgr10L$formula,PLS.lgr11L$formula,PLS.lgr12L$formula,PLS.lgr13L$formula, PLS.lgr14L$formula )

AIC2.df<- AIC2.df[order(AIC2.df$AIC),]
library(knitr)
library(pander)
AIC2.df$model <- rownames(AIC2.df)

#calculate prediction error:
msqe.code<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$ecocode - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC2.df$MSPE <- 1

#add prediction error ot AIC dataframe

for (i in 1: length(AIC2.df$model)){
AIC2.df[i,'MSPE'] <- msqe.code(get(AIC2.df[i,"model"]), test)
}
pander(AIC2.df[,c("model","modeltype", "formula", "df", "AIC", "MSPE")], split.cells = 30)

logsample <- predict(PLS.lgr14, test, type="response")
test$ypred <- logsample
summary(logsample)
hist(test$ypred)

ggplot(test, aes(MAP1910, ypred, color = ypred)) + geom_point()
ggplot(test, aes(x, y, color = ypred)) + geom_point()


```
Looks like model number 14 with just Mean Annual Precipitation has lowest AIC for the logistic/binomial model. 
Lets map out the probability of forest based on model with the lowest AIC value:

forest type ~ s(MAP1910)+ s(pasttmean) + s(deltaT) +   s(pastdeltaP)

The smooth predictors in this model are the same as the smooth predictors in the denisty model

# savanna forest model for FIA:
```{r echo = FALSE, warning = FALSE}

# dummyvariables for logistic regression:
fiadens$ecocode <- 0
fiadens[fiadens$ecotype %in% 'Forest', ]$ecocode <- 1
#fiadens<- fiadens[!fiadens$ecotype %in% 'prairie',]

#split trainffing and testfing
Y <- fiadens$ecotype
msk <- sample.split( Y, SplitRatio = 1/4, group = NULL )
#table(Y,msk)

trainf <- fiadens[msk,]
testf <- fiadens[!msk,]


#plot(fiadens$sandpct, fiadens$ecotype)


FIA.lgr1 <-gam(ecocode ~  s(MAP1910), family = 'binomial',data = trainf)
FIA.lgr1L <-gam(ecocode ~  MAP1910, family = 'binomial',data = trainf)


FIA.lgr2 <- gam(ecocode ~ s(pasttmean) , family = 'binomial',data = trainf)
FIA.lgr2L <- gam(ecocode ~ pasttmean , family = 'binomial',data = trainf)
#summary(FIA.lgr2) #explains 15.8% deviance
#plot(FIA.lgr2)

FIA.lgr3 <- gam(ecocode ~ s(pastdeltaP), family = 'binomial',data = trainf)
FIA.lgr3L <- gam(ecocode ~ pastdeltaP, family = 'binomial',data = trainf)
#summary(FIA.lgr3) #explains 6.07% deviance

FIA.lgr4 <- gam(ecocode ~ s(deltaT), family = 'binomial',data = trainf)
FIA.lgr4L <- gam(ecocode ~ deltaT, family = 'binomial',data = trainf)
#summary(FIA.lgr4) #explains 6.07% deviance

FIA.lgr5 <- gam(ecocode ~ s(awc), family = 'binomial',data = trainf)
FIA.lgr5L <- gam(ecocode ~ awc, family = 'binomial',data = trainf)
#summary(FIA.lgr5) #explains 12.5% of deviance

FIA.lgr6 <- gam(ecocode ~ s(sandpct), family = 'binomial',data = trainf)
FIA.lgr6L <- gam(ecocode ~ sandpct, family = 'binomial',data = trainf)
#summary(FIA.lgr6) #explains 12.5% of deviance



FIA.lgr7 <- gam(ecocode ~ s(pasttmean) + s(MAP1910) ,  family = 'binomial',data = trainf)
FIA.lgr7L <- gam(ecocode ~ pasttmean + MAP1910 ,  family = 'binomial',data = trainf)
#summary(FIA.lgr7) #explains 41% deviance
#summary(FIA.lgr7L) # explains 19.6%

FIA.lgr8 <- gam(ecocode ~ s(awc) +s(sandpct), family = 'binomial',data = trainf )
FIA.lgr8L <- gam(ecocode ~ awc + sandpct, family = 'binomial',data = trainf )
#summary(FIA.lgr8) #explains 28% of deviance

FIA.lgr9 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = 'binomial',data = trainf)
FIA.lgr9L <- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = 'binomial',data = trainf)
#summary(FIA.lgr9) #explains 39% deviance
#summary(FIA.lgr9L)
#plot(FIA.lgr6)


FIA.lgr10 <- gam(ecocode ~ s(MAP1910) +s(pasttmean) + s(awc), family = 'binomial',data = trainf)
FIA.lgr10L <- gam(ecocode ~ MAP1910 + pasttmean + awc, family = 'binomial',data = trainf)

#summary(FIA.lgr10) #explains 41.3% of deviance
#plot(FIA.lgr10)

FIA.lgr11 <- gam(ecocode ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), family = 'binomial',data = trainf)
FIA.lgr11L <- gam(ecocode ~ MAP1910  + pasttmean + sandpct + awc, family = 'binomial',data = trainf)

#summary(FIA.lgr8) # explains 41% of deviance
FIA.lgr12 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP),family = 'binomial', data = trainf)
FIA.lgr12L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = trainf)

FIA.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), family = 'binomial',data = trainf)
FIA.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + pastdeltaP, family = 'binomial',data = trainf)

#FIA.lgr13 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT), family = 'binomial',data = trainf)
#FIA.lgr13L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT, family = 'binomial',data = trainf)

FIA.lgr14 <- gam(ecocode ~ s(MAP1910)  + s(pasttmean) + s(deltaT) + s(pastdeltaP)+s(sandpct)+s(awc), family = 'binomial',data = trainf)
FIA.lgr14L <- gam(ecocode ~ MAP1910  + pasttmean + deltaT + pastdeltaP, family = 'binomial',data = trainf)

AIC2.df<- AIC(FIA.lgr1, FIA.lgr2, FIA.lgr3, FIA.lgr4, FIA.lgr5, FIA.lgr6, FIA.lgr7, FIA.lgr8, FIA.lgr9,FIA.lgr10,FIA.lgr11,FIA.lgr12,FIA.lgr13,FIA.lgr14 , FIA.lgr1L, FIA.lgr2L, FIA.lgr3L, FIA.lgr4L, FIA.lgr5L, FIA.lgr6L, FIA.lgr7L, FIA.lgr8L, FIA.lgr9L, FIA.lgr10L,FIA.lgr11L,FIA.lgr12L,FIA.lgr13L,FIA.lgr14L)




AIC2.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))

AIC2.df$formula <- c(FIA.lgr1$formula, FIA.lgr2$formula, FIA.lgr3$formula, FIA.lgr4$formula, FIA.lgr5$formula, FIA.lgr6$formula, FIA.lgr7$formula, FIA.lgr8$formula, FIA.lgr9$formula,FIA.lgr10$formula,FIA.lgr11$formula,FIA.lgr12$formula,FIA.lgr13$formula,FIA.lgr14$formula , FIA.lgr1L$formula, FIA.lgr2L$formula, FIA.lgr3L$formula, FIA.lgr4L$formula, FIA.lgr5L$formula, FIA.lgr6L$formula, FIA.lgr7L$formula, FIA.lgr8L$formula, FIA.lgr9L$formula, FIA.lgr10L$formula,FIA.lgr11L$formula,FIA.lgr12L$formula,FIA.lgr13L$formula, FIA.lgr14L$formula )

AIC2.df<- AIC2.df[order(AIC2.df$AIC),]
library(knitr)
library(pander)
AIC2.df$model <- rownames(AIC2.df)

#calculate prediction error:
msqe.code<- function(model, testfdata){
ypred <- predict(model, newdata = testfdata, type="response")
testfdata$ypred <- ypred

predicted<- testfdata
  
predicted$sqerr <- (predicted$ecocode - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

AIC2.df$MSPE <- 1

#add prediction error ot AIC dataframe

for (i in 1: length(AIC2.df$model)){
AIC2.df[i,'MSPE'] <- msqe.code(get(AIC2.df[i,"model"]), test)
}
pander(AIC2.df[,c("model","modeltype", "formula", "df", "AIC", "MSPE")], split.cells = 30)


```
