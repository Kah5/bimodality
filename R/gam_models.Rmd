---
title: "Exploring models for PLS density"
author: "Kelly Heilman"
date: "January 25, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Thinking about model design:

Ideally, we want to model denisty or savanna/forest 

model density ~ f(environmental variables)
density ~ smooth(MAP) (in previous versions, climate was negative correlated with density??)
density ~ smooth(temp)
density ~ smooth(soil/sand)
density ~ smooth(precip. seasonality)
density ~ smooth(temp. seasonality)
density ~ smooth(MAP + temp)
density ~ smooth(MAP) + smooth(temp) + smooth(soil)

Generalized additive model: allows for non-linearities...

Alternatively, we could us the classification scheme of savanna and forest; this isn't as great, but it would allow us to use a logistic model, and to model the probability of forest, rather than tree density.

Model Selection/Cross Validation Options:

* leave one out CV (for gam's, the GCV value is similar), it may not be feasible to do this for our # of data points
* for now, we split into test and training 50/50
* Use information criterion AIC (min)
* Need to decide whether Model prediction should be on PLS density or on PLS classification (savanna vs. forest)?

```{r, echo = FALSE}
library(stargazer)
library(mgcv)
library(caTools)
library(ggplot2)

#dens.pr <- read.csv("data/midwest_pls_density_pr_alb1.6-5.csv") # just with grid cells that have both pls & FIA
dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") # full set of PLS data
#hist(dens.pr$PLSdensity, breaks = 50)

#pls.new <- dens.pr[dens.pr$PLSdensity > 0,] # remove all 0 values for now
#dens.pr <- pls.new 
# split into test and training datasets:
Y <- dens.pr$PLSdensity
msk <- sample.split( Y, SplitRatio = 1/2, group = NULL )
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]




PLS.gam1 <-gam(PLSdensity ~  s(MAP1910), data = train)
PLS.gam1L <-gam(PLSdensity ~  MAP1910, data = train)
#summary(PLS.gam1) #explains 0.004% deviance
#preds <- predict(PLS.gam1, newdata = test)
#predsL <- predict(PLS.gam1L, newdata = test)
#plot(preds, test$PLSdensity)
#plot(predsL, test$PLSdensity)
#plot(PLS.gam1)


#test$preds <- preds
#ggplot(test, aes(x = x, y = y, color = preds))+geom_point()+scale_color_gradient(low = "red", high="green")

#plot(preds, test$PLSdensity, xlim = c(0,700), ylim=c(0,700))
#test[is.na(test$preds),]$preds<- 0 

#test$predeco <- 0
#test[test$preds >=47,]$predeco <- "Forest"
#test[test$preds <47,]$predeco <- "Savanna"
#test[test$preds <0.5,]$predeco <- "prairie"

#plot(test$MAP1910, preds) # plot predicted vs map function
#plot(test$MAP1910, predsL)
#plot(test$pasttmean, preds) # plot predicted vs past tmean function
#plot(test$sandpct, preds) # plot precicted vs. sand function
#test$po <- preds - test$PLSdensity
#ggplot(test, aes(x = x, y = y, color = po))+geom_point()+scale_color_gradient(low = "red", high="green")

#ggplot(test, aes(x = MAP1910, y = pasttmean, color = preds))+geom_point()+scale_color_gradient(low = "red", high="green")

#ggplot(test, aes(x = x, y = y, color = predeco))+geom_point()


#ggplot(test, aes(x = PLSdensity, y = preds, color = predeco)) + geom_point()

#plot(train$MAP1910, train$PLSdensity)





PLS.gam2 <- gam(PLSdensity ~ s(pasttmean) , data = train)
PLS.gam2L <- gam(PLSdensity ~ pasttmean , data = train)
#summary(PLS.gam2) #explains 15.8% deviance
#plot(PLS.gam2)

PLS.gam3 <- gam(PLSdensity ~ s(pastdeltaP), data = train)
PLS.gam3L <- gam(PLSdensity ~ pastdeltaP, data = train)
#summary(PLS.gam3) #explains 6.07% deviance

PLS.gam4 <- gam(PLSdensity ~ s(pastdeltaT), data = train)
PLS.gam4L <- gam(PLSdensity ~ pastdeltaT, data = train)
#summary(PLS.gam4) #explains 6.07% deviance

PLS.gam5 <- gam(PLSdensity ~ s(awc), data = train)
PLS.gam5L <- gam(PLSdensity ~ awc, data = train)
#summary(PLS.gam5) #explains 12.5% of deviance

PLS.gam6 <- gam(PLSdensity ~ s(sandpct), data = train)
PLS.gam6L <- gam(PLSdensity ~ sandpct, data = train)
#summary(PLS.gam6) #explains 12.5% of deviance



PLS.gam7 <- gam(PLSdensity ~ s(pasttmean) + s(MAP1910) ,  data = train)
PLS.gam7L <- gam(PLSdensity ~ pasttmean + MAP1910 ,  data = train)
#summary(PLS.gam7) #explains 41% deviance
#summary(PLS.gam7L) # explains 19.6%

PLS.gam8 <- gam(PLSdensity ~ s(awc) +s(sandpct), data = train )
PLS.gam8L <- gam(PLSdensity ~ awc + sandpct, data = train )
#summary(PLS.gam8) #explains 28% of deviance

PLS.gam9 <- gam(PLSdensity ~ s(MAP1910) + s(pasttmean) + s(sandpct), data = train)
PLS.gam9L <- gam(PLSdensity ~ MAP1910 + pasttmean + sandpct, data = train)
#summary(PLS.gam9) #explains 39% deviance
#summary(PLS.gam9L)
#plot(PLS.gam6)


PLS.gam10 <- gam(PLSdensity ~ s(MAP1910) +s(pasttmean) + s(awc), data = train)
PLS.gam10L <- gam(PLSdensity ~ MAP1910 + pasttmean + awc, data = train)

#summary(PLS.gam10) #explains 41.3% of deviance
#plot(PLS.gam10)

PLS.gam11 <- gam(PLSdensity ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), data = train)
PLS.gam11L <- gam(PLSdensity ~ MAP1910  + pasttmean + sandpct + awc, data = train)

#summary(PLS.gam8) # explains 41% of deviance
PLS.gam12 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam12L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaT), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaT, data = train)

PLS.gam14 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaT) + s(pastdeltaP), data = train)
PLS.gam14L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaT + pastdeltaP, data = train)

AIC.df<- AIC(PLS.gam1, PLS.gam2, PLS.gam3, PLS.gam4, PLS.gam5, PLS.gam6, PLS.gam7, PLS.gam8, PLS.gam9,PLS.gam10,PLS.gam11,PLS.gam12,PLS.gam13,PLS.gam14 , PLS.gam1L, PLS.gam2L, PLS.gam3L, PLS.gam4L, PLS.gam5L, PLS.gam6L, PLS.gam7L, PLS.gam8L, PLS.gam9L, PLS.gam10L,PLS.gam11L,PLS.gam12L,PLS.gam13L,PLS.gam14L)

AIC.df$modeltype <- c(rep('smooth', 14), rep('linear', 14))
AIC.df$formula <- c(PLS.gam1$formula, PLS.gam2$formula, PLS.gam3$formula, PLS.gam4$formula, PLS.gam5$formula, PLS.gam6$formula, PLS.gam7$formula, PLS.gam8$formula, PLS.gam9$formula,PLS.gam10$formula,PLS.gam11$formula,PLS.gam12$formula,PLS.gam13$formula,PLS.gam14$formula , PLS.gam1L$formula, PLS.gam2L$formula, PLS.gam3L$formula, PLS.gam4L$formula, PLS.gam5L$formula, PLS.gam6L$formula, PLS.gam7L$formula, PLS.gam8L$formula, PLS.gam9L$formula, PLS.gam10L$formula,PLS.gam11L$formula,PLS.gam12L$formula,PLS.gam13L$formula, PLS.gam14L$formula )

library(knitr)
library(pander)
AIC.df$model <- rownames(AIC.df)


pander(AIC.df[,c("model","modeltype", "formula", "df", "AIC")], split.cells = 30)

```

PLS gam 11 model has the lowest AIC includes precipitation, mean temperature, Temp. seasonality, precipitation seasonality in in has lowest AIC value. How does this model predict the PLS test data?

Well, there are a couple of things to think about:
1. predictions are occassionally negative
2. predication range is not as high as the observed range
3. most models overestimate density at low density regions and underestimate density in high denisty regions
4. Many of the above AIC's are very similar, so the benefit of adding an additional term may be marginal.

```{r}
require(np)
data(oecdpanel)

dens.pr<- dens.pr[1:100,]
# Compare predictive ability using five-fold CV
nfolds <- nrow(dens.pr)
case.folds <- rep(1:nfolds,length.out=nrow(dens.pr))
    # divide the cases as evenly as possible
case.folds <- sample(case.folds) # randomly permute the order
#bandwidths <- (1:5)/10 # Evenly space bandwidths from 0.1 to 0.5
fold.mses <- matrix(0,nrow=nfolds,ncol=1)
#colnames(fold.mses) = as.character(bandwidths)
   # By naming the columns, we'll won't have to keep track of which bandwidth
   # is in which position
for (fold in 1:nfolds) {
  # What are the training cases and what are the test cases?
  train <- dens.pr[case.folds!=fold,]
  test <- dens.pr[case.folds==fold,]
    # Fit to the training set
    current.npr <- lm(PLSdensity ~ sandpct, data=train)
    # Predict on the test set
    predictions <- predict(current.npr, newdata=test)
    # What's the mean-squared error?
    fold.mses[fold,] <- mean((test$PLSdensity - predictions)^2)
    # Using paste() here lets us access the column with the right name...
  }

# Average the MSEs
head(fold.mses) 

```


```{r, echo = FALSE}
library(maps)
library(sp)
library(rgeos)
library(visreg)
all_states <- map_data("state")
states <- subset(all_states, region %in% c(  'minnesota','wisconsin','michigan',"illinois",  'indiana') )
coordinates(states)<-~long+lat
class(states)
proj4string(states) <-CRS("+proj=longlat +datum=NAD83")
mapdata<-spTransform(states, CRS('+init=epsg:3175'))
mapdata <- data.frame(mapdata)
cbpalette <- c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837")
#map out 

# plot the predicted response fields to these variables

#visreg2d(PLS.gam11, xvar='MAP1910', yvar='pasttmean', scale='response')
#visreg2d(PLS.gam11, xvar='MAP1910', yvar='pastdeltaP', scale='response')
#visreg2d(PLS.gam11, xvar='MAP1910', yvar='pastdeltaT', scale='response')

map.pred.density <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
plot(testdata$MAP1910, ypred, pch = 16, xlab = "MAP", ylab = "Predicted")

plot(testdata$pasttmean, ypred, pch = 16, xlab = "pasttmean", ylab = "Predicted")

testdata$ypred <- ypred

all_states <- map_data("state")
states <- subset(all_states, region %in% c(  'minnesota','wisconsin','michigan',"illinois",  'indiana') )
coordinates(states)<-~long+lat
class(states)
proj4string(states) <-CRS("+proj=longlat +datum=NAD83")
mapdata<-spTransform(states, CRS('+init=epsg:3175'))
mapdata <- data.frame(mapdata)
cbpalette <- c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837")

ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=testdata, aes(x=x, y=y, fill = ypred))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="Predicted tree density") + 
  scale_fill_gradientn(colours = c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837"), limits = c(0,700), name ="Tree \n Density \n (trees/hectare)", na.value = 'darkgrey') +
  coord_equal()+theme_bw()
#outdata <- testdata
}

# make a function to extracted predictions from a model
get.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")

testdata$ypred <- ypred

testdata
}

predicted <- get.preds(PLS.gam11, test)
summary(predicted$ypred)

predicted <- get.preds(PLS.gam14L, test)
summary(predicted$ypred)

#calcuated the squared error for each prediction
msqe<- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
testdata$ypred <- ypred

predicted<- testdata
  
predicted$sqerr <- (predicted$PLSdensity - predicted$ypred)^2
mean(predicted$sqerr, na.rm = TRUE)
}

msqe(PLS.gam14L, test)
msqe(PLS.gam13L, test)
msqe(PLS.gam12L, test)
msqe(PLS.gam11L, test)
msqe(PLS.gam10L, test)

msqe(PLS.gam14, test)
msqe(PLS.gam13, test)
msqe(PLS.gam12, test)
msqe(PLS.gam11, test)
msqe(PLS.gam10, test)


# plot the predicted tree denisty in the map
ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=predicted, aes(x=x, y=y, fill = ypred))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="Predicted tree density from Model 11") + 
  scale_fill_gradientn(colours = c("#ffffcc", "#c2e699", "#78c679", "#31a354", "#006837"), limits = c(0,700), name ="Tree \n Density \n (trees/hectare)", na.value = 'darkgrey') +
  coord_equal()+theme_bw()


# plot predicted vs. observed (color by sand content)
ggplot(predicted, aes(PLSdensity,ypred, color = sandpct)) +geom_point() + theme_bw()+geom_abline(intercept = 0, slope = 1, color = 'red', size = 2) + ylim (-5, 600) + ggtitle('Predicted vs. Observed') + ylab('Predicted tree density') + xlab('Observed tree density')



# calculate predicted - observed
predicted$podiff <- predicted$ypred - predicted$PLSdensity

# map out predicted - observed
ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=predicted, aes(x=x, y=y, fill = podiff))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="Predicted - Obs from Model 11") +  scale_fill_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') +
  coord_equal()+theme_bw()

# plotting predicted - observed in different climate spaces
ggplot() + geom_point(data = predicted, aes(x= MAP1910, y = pasttmean, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') 

ggplot() + geom_point(data = predicted, aes(x= MAP1910, y = sandpct, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') 

ggplot() + geom_point(data = predicted, aes(x= MAP1910, y = awc, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') 

ggplot() + geom_point(data = predicted, aes(x= pasttmean, y = awc, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') 

ggplot() + geom_point(data = predicted, aes(x= pasttmean, y = awc, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') 


# histograms of soil variables
hist(predicted$sandpct, breaks = 50)

hist(predicted$awc, breaks = 50)

# break up the dataset by sand % 
predicted$sandgroup <- '59-88%'
predicted[predicted$sandpct <59.04,]$sandgroup <- '29-59%'
predicted[predicted$sandpct < 29.52,]$sandgroup <- '0-29%'

# plot 3 bins of sand:
ggplot() + geom_histogram(data = predicted, aes(x= sandpct))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') +facet_grid(~sandgroup)

# plot the predicted - obs by bins of sand
ggplot() + geom_point(data = predicted, aes(x= pasttmean, y = MAP1910, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs )", na.value = 'darkgrey') +facet_grid(~sandgroup)

# plot the predicted by bins of sand
ggplot() + geom_point(data = predicted, aes(x= pasttmean, y = MAP1910, color = ypred))+ scale_color_gradientn(colours = rainbow(7), name ="Pred", na.value = 'darkgrey') +facet_grid(~sandgroup)



# do the same for temperature:
hist(predicted$pasttmean, breaks = 50)

predictedt <- predicted[complete.cases(predicted),]

# break up the dataset by temperatiure 
predictedt$tempgroup <- '9-14'
predictedt[predictedt$pasttmean < 9,]$tempgroup <- '5-9'
predictedt[predictedt$pasttmean < 5,]$tempgroup <- '0-5'

# plot 3 bins of sand:
ggplot() + geom_histogram(data = predictedt, aes(x= pasttmean))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs ", na.value = 'darkgrey') +facet_grid(~tempgroup)

# plot the predicted - obs by bins of sand
ggplot() + geom_point(data = predictedt, aes(x= sandpct, y = MAP1910, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs ", na.value = 'darkgrey') +facet_grid(~tempgroup)

# plot the predicted - obs by bins of pasttmean
ggplot() + geom_point(data = predictedt, aes(x= awc, y = MAP1910, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs", na.value = 'darkgrey') +facet_grid(~tempgroup)




# do the same for precipitation:
hist(predicted$MAP1910, breaks = 50)

predictedp <- predicted[complete.cases(predicted),]

# break up the dataset by temperatiure 
predictedp$pgroup <- '900-1200'
predictedp[predictedp$MAP1910 < 900,]$pgroup <- '700-900'
predictedp[predictedp$MAP1910 < 700,]$pgroup <- '450-700'

# plot 3 bins of precip:
ggplot() + geom_histogram(data = predictedp, aes(x= MAP1910))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs ", na.value = 'darkgrey') +facet_grid(~pgroup)

# plot the predicted - obs by bins of precip
ggplot() + geom_point(data = predictedp, aes(x= sandpct, y = pasttmean, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs ", na.value = 'darkgrey') +facet_grid(~pgroup)

# plot the predicted - obs by bins of precip
ggplot() + geom_point(data = predictedp, aes(x= awc, y = pasttmean, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs", na.value = 'darkgrey') +facet_grid(~pgroup)


# do the same for AWC:
hist(predicted$awc, breaks = 50)

predicteda <- predicted[complete.cases(predicted),]

# break up the dataset by temperatiure 
predicteda$agroup <- '0.18-0.226'
predicteda[predicteda$awc < 0.18,]$agroup <- '0.14-0.18'
predicteda[predicteda$awc < 0.14,]$agroup <- '0-0.14'

# plot 3 bins of precip:
ggplot() + geom_histogram(data = predicteda, aes(x= awc))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs ", na.value = 'darkgrey') +facet_grid(~agroup)

# plot the predicted - obs by bins of precip
ggplot() + geom_point(data = predicteda, aes(x= sandpct, y = pasttmean, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs ", na.value = 'darkgrey') +facet_grid(~agroup)

# plot the predicted - obs by bins of precip
ggplot() + geom_point(data = predicteda, aes(x= MAP1910, y = pasttmean, color = podiff))+ scale_color_gradientn(colours = rainbow(7), name ="Pred - obs", na.value = 'darkgrey') +facet_grid(~agroup)


```
So far, the under and over estimation of the model doesn't appear systematic from these graphs, but it is hard to tell. For example, there seems to be a high amount of overestimateion at low AWC & intermediate precipitation (and 4-7 degC mean annual temperature).

## Predicting Forest vs. Savanna (not density)

The above models are predicting density (continious variable) from continous envrionmental and climate covariates. However, we can also use the savanna/forest density classificaitons as our y variable and  predict the probability a grid cell is forest (ecocode = 1, PLS density > 47 trees/ha) and savannna(ecocode = 0, PLSdensity < 47 trees/ha & >0.5 trees/ha) from continous environmental and climate covariates. 

In this case we model 

This method has the benefit of predicting the probability of forest (or the probability of savanna) given certain environmental conditions. For this analysis, we exclude prairie sites

```{r echo = FALSE}
#test logistic regressoin
# dummyvariables for logistic regression:
dens.pr$ecocode <- 0
dens.pr[dens.pr$ecotype %in% 'Forest', ]$ecocode <- 1
dens.pr<- dens.pr[!dens.pr$ecotype %in% 'prairie',]
#split training and testing
Y <- dens.pr$PLSdensity
msk <- sample.split( Y, SplitRatio = 1/2, group = NULL )
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]


#plot(dens.pr$sandpct, dens.pr$ecotype)


# developing binomial gam models
logmod<- gam(ecocode ~ s(MAP1910) , family = binomial, data = train)

logmodL <- gam(ecocode ~ MAP1910 , family = binomial, data = train)
#summary(logmod)
#plot(logmod)




logmod2<- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = binomial, data = train)

logmod2L<- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = binomial, data = train)

#summary(logmod2)
#summary(logmod2L)
#plot(logmod2)

logmod3 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(pastdeltaP)+ s(sandpct), family = binomial, data = train)

logmod3L <- gam(ecocode ~ MAP1910 + pasttmean + pastdeltaP+ sandpct, family = binomial, data = train)

#summary(logmod3L)
#summary(logmod3)
#plot(logmod3)

ypred3 <- predict(logmod3, newdata = test, type="response")
#plot(test$MAP1910, ypred3, pch = 16, xlab = "MAP", ylab = "Predicted")

logmod4 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(pastdeltaP)+ s(pastdeltaT) + s(sandpct), family = binomial, data = train)

logmod4L <- gam(ecocode ~ MAP1910 + pasttmean + pastdeltaP+ pastdeltaT + sandpct, family = binomial, data = train)

#summary(logmod4)
#plot(logmod4)

ypred4 <- predict(logmod4, newdata = test, type="response")
#plot(test$MAP1910, ypred4, pch = 16, xlab = "MAP", ylab = "Predicted")

logmod5<- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(pastdeltaP)+ s(pastdeltaT) + s(sandpct) + s(awc), family = binomial, data = train)

logmod5L <- gam(ecocode ~ MAP1910 + pasttmean + pastdeltaP+ pastdeltaT + sandpct + awc, family = binomial, data = train)

#summary(logmod5)
#plot(logmod5)

ypred5 <- predict(logmod5, newdata = test, type="response")
#plot(test$MAP1910, ypred5, pch = 16, xlab = "MAP", ylab = "Predicted")

#plot predicted probabiliy of forest vs. observed tree density
#plot(test$PLSdensity, ypred5, pch = 16, xlab = "obs", ylab = "Predicted")

AIC2.df<- AIC(logmod, logmod2, logmod3, logmod4, logmod5, 
    logmodL, logmod2L, logmod3L, logmod4L, logmod5L)



AIC2.df$modeltype <- c(rep('smooth', 5), rep('linear', 5))
AIC2.df$formula <- c(logmod$formula, logmod2$formula, logmod3$formula, logmod4$formula, logmod5$formula, 
    logmodL$formula, logmod2L$formula, logmod3L$formula, logmod4L$formula, logmod5L$formula)

library(knitr)
library(pander)
AIC2.df$model <- rownames(AIC2.df)


pander(AIC2.df[,c("model","modeltype", "formula", "df", "AIC")], split.cells = 30)
```
Looks like model number 5 has lowest AIC for the logistic/binomial model. 
Lets map out the probability of forest based on model with the lowest AIC value:
```{r, echo = FALSE}

library(visreg)
map.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
plot(testdata$MAP1910, ypred, pch = 16, xlab = "MAP", ylab = "Predicted")

plot(testdata$pasttmean, ypred, pch = 16, xlab = "pasttmean", ylab = "Predicted")

testdata$ypred <- ypred
ggplot(testdata, aes(x = x, y = y, color = ypred))+geom_point() + theme_bw() +ggtitle ('Probability of forest') 
#outdata <- testdata
}

get.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")

testdata$ypred <- as.vector(ypred)

testdata
}

map.preds(logmod5, test)

preds.df <- data.frame(get.preds(logmod5, test))
hist(preds.df$ypred, breaks = 25)
summary(preds.df$ypred)

# plot the predicted response to these variables

#visreg2d(logmod5, xvar='MAP1910', yvar='pasttmean', scale='response')
#visreg2d(logmod5, xvar='MAP1910', yvar='pastdeltaP', scale='response')
#visreg2d(logmod5, xvar='MAP1910', yvar='pastdeltaT', scale='response')
#visreg2d(logmod5, xvar='MAP1910', yvar='sandpct', scale='response')
#visreg2d(logmod5, xvar='MAP1910', yvar='awc', scale='response')


preds.df$predcode <- "savanna"
preds.df <- preds.df[complete.cases(preds.df),]
preds.df[preds.df$ypred < 0.7,]$predcode <- "savanna or forest"
preds.df[preds.df$ypred > 0.3,]$predcode <- "savanna or forest"
preds.df[preds.df$ypred >= 0.7,]$predcode <- "forest"
preds.df[preds.df$ypred <= 0.3,]$predcode <- "savanna"


#ggplot(preds.df, aes(x, y, color = predcode)) + geom_point() + theme_bw()

ggplot()+ geom_polygon(data = mapdata, aes(group = group,x=long, y =lat), fill = 'darkgrey')+
  geom_raster(data=preds.df, aes(x=x, y=y, fill = predcode))+
  geom_polygon(data = mapdata, aes(group = group,x=long, y =lat),colour="black", fill = NA)+
  labs(x="easting", y="northing", title="Probability of forest from Model 5") + scale_fill_manual(values = c(
      #, # light green
      'red', # dark teal
      '#8c510a', # red
      #'#d8b365', # light tan
      'forestgreen',
      #'#fee08b', # tan
      '#01665e',
      'black'), limits = c('savanna or forest' ,'savanna', 'forest'))+
    theme_bw()+
  coord_equal()+theme_bw()

```

The above map shows 'savana or forest' places where the binomial familiy model predicted between 30-70% probability of forest. There are some places where the model predicts deterministic forest and deterministic savanna. 
