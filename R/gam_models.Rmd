---
title: "Gam_model"
author: "Kelly Heilman"
date: "January 25, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Thinking about model design:

model density ~ f(environmental variables)
density ~ smooth(MAP) (in previous versions, climate was negative correlated with density??)
density ~ smooth(temp)
density ~ smooth(soil/sand)
density ~ smooth(precip. seasonality)
density ~ smooth(temp. seasonality)
density ~ smooth(MAP + temp)
density ~ smooth(MAP) + smooth(temp) + smooth(soil)

Generalized additive model: allows for non-linearities...

Alternatively, we could us the classification scheme of savanna and forest; this isn't as great, but it would allow us to use a logistic model:

Cross Validation Options:

* leave one out CV (for gam's, the GCV value is similar), it may not be feasible to do this for our # of data points
* for now, we split into test and training 50/50
* Use information criterion AIC (min)
* Need to decide whether Model prediction should be on PLS density or on PLS classification (savanna vs. forest)?

```{r, echo = FALSE}
library(stargazer)
library(mgcv)
library(caTools)
library(ggplot2)

#dens.pr <- read.csv("data/midwest_pls_density_pr_alb1.6-5.csv") # just with grid cells that have both pls & FIA
dens.pr <- read.csv("C:/Users/JMac/Documents/Kelly/biomodality/data/midwest_pls_full_density_pr_alb1.6-5.csv") # full set of PLS data
hist(dens.pr$PLSdensity, breaks = 50)

pls.new <- dens.pr[dens.pr$PLSdensity > 0,] # remove all 0 values for now
dens.pr <- pls.new 
# split into test and training datasets:
Y <- dens.pr$PLSdensity
msk <- sample.split( Y, SplitRatio = 1/2, group = NULL )
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]




PLS.gam1 <-gam(PLSdensity ~  s(MAP1910), data = train)
PLS.gam1L <-gam(PLSdensity ~  MAP1910, data = train)
summary(PLS.gam1) #explains 0.004% deviance
preds <- predict(PLS.gam1, newdata = test)
predsL <- predict(PLS.gam1L, newdata = test)
plot(preds, test$PLSdensity)
plot(predsL, test$PLSdensity)
plot(PLS.gam1)


test$preds <- preds
ggplot(test, aes(x = x, y = y, color = preds))+geom_point()+scale_color_gradient(low = "red", high="green")

plot(preds, test$PLSdensity, xlim = c(0,700), ylim=c(0,700))
test[is.na(test$preds),]$preds<- 0 

#test$predeco <- 0
#test[test$preds >=47,]$predeco <- "Forest"
#test[test$preds <47,]$predeco <- "Savanna"
#test[test$preds <0.5,]$predeco <- "prairie"

plot(test$MAP1910, preds) # plot predicted vs map function
plot(test$MAP1910, predsL)
plot(test$pasttmean, preds) # plot predicted vs past tmean function
plot(test$sandpct, preds) # plot precicted vs. sand function
test$po <- preds - test$PLSdensity
ggplot(test, aes(x = x, y = y, color = po))+geom_point()+scale_color_gradient(low = "red", high="green")

ggplot(test, aes(x = MAP1910, y = pasttmean, color = preds))+geom_point()+scale_color_gradient(low = "red", high="green")

#ggplot(test, aes(x = x, y = y, color = predeco))+geom_point()


#ggplot(test, aes(x = PLSdensity, y = preds, color = predeco)) + geom_point()

plot(train$MAP1910, train$PLSdensity)





PLS.gam2 <- gam(PLSdensity ~ s(pasttmean) , data = train)
PLS.gam2L <- gam(PLSdensity ~ pasttmean , data = train)
summary(PLS.gam2) #explains 15.8% deviance
plot(PLS.gam2)

PLS.gam3 <- gam(PLSdensity ~ s(pastdeltaP), data = train)
PLS.gam3L <- gam(PLSdensity ~ pastdeltaP, data = train)
summary(PLS.gam3) #explains 6.07% deviance

PLS.gam4 <- gam(PLSdensity ~ s(pastdeltaT), data = train)
PLS.gam4L <- gam(PLSdensity ~ pastdeltaT, data = train)
summary(PLS.gam4) #explains 6.07% deviance

PLS.gam5 <- gam(PLSdensity ~ s(awc), data = train)
PLS.gam5L <- gam(PLSdensity ~ awc, data = train)
summary(PLS.gam5) #explains 12.5% of deviance

PLS.gam6 <- gam(PLSdensity ~ s(sandpct), data = train)
PLS.gam6L <- gam(PLSdensity ~ sandpct, data = train)
summary(PLS.gam6) #explains 12.5% of deviance



PLS.gam7 <- gam(PLSdensity ~ s(pasttmean) + s(MAP1910) ,  data = train)
PLS.gam7L <- gam(PLSdensity ~ pasttmean + MAP1910 ,  data = train)
summary(PLS.gam7) #explains 41% deviance
summary(PLS.gam7L) # explains 19.6%

PLS.gam8 <- gam(PLSdensity ~ s(awc) +s(sandpct), data = train )
PLS.gam8L <- gam(PLSdensity ~ awc + sandpct, data = train )
summary(PLS.gam8) #explains 28% of deviance

PLS.gam9 <- gam(PLSdensity ~ s(MAP1910) + s(pasttmean) + s(sandpct), data = train)
PLS.gam9L <- gam(PLSdensity ~ MAP1910 + pasttmean + sandpct, data = train)
summary(PLS.gam9) #explains 39% deviance
summary(PLS.gam9L)
#plot(PLS.gam6)


PLS.gam10 <- gam(PLSdensity ~ s(MAP1910) +s(pasttmean) + s(awc), data = train)
PLS.gam10L <- gam(PLSdensity ~ MAP1910 + pasttmean + awc, data = train)

summary(PLS.gam10) #explains 41.3% of deviance
plot(PLS.gam10)

PLS.gam11 <- gam(PLSdensity ~ s(MAP1910)  +s(pasttmean) +s(sandpct) + s(awc), data = train)
PLS.gam11L <- gam(PLSdensity ~ MAP1910  + pasttmean + sandpct + awc, data = train)

#summary(PLS.gam8) # explains 41% of deviance
PLS.gam12 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam12L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaP), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaP, data = train)

PLS.gam13 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaT), data = train)
PLS.gam13L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaT, data = train)

PLS.gam14 <- gam(PLSdensity ~ s(MAP1910)  + s(pasttmean) + s(pastdeltaT) + s(pastdeltaP), data = train)
PLS.gam14L <- gam(PLSdensity ~ MAP1910  + pasttmean + pastdeltaT + pastdeltaP, data = train)

AIC.df<- AIC(PLS.gam1, PLS.gam2, PLS.gam3, PLS.gam4, PLS.gam5, PLS.gam6, PLS.gam7, PLS.gam8, PLS.gam9,PLS.gam10,PLS.gam11,PLS.gam12,PLS.gam13,PLS.gam14 , PLS.gam1L, PLS.gam2L, PLS.gam3L, PLS.gam4L, PLS.gam5L, PLS.gam6L, PLS.gam7L, PLS.gam8L, PLS.gam9L, PLS.gam10L,PLS.gam11L,PLS.gam12L,PLS.gam13L,PLS.gam14L)

AIC.df
```
# PLS gam 14 model that includes precipitation, mean temperature, Temp. seasonality, precipitation seasonality in in has lowest AIC value. How does this model predict the PLS test data?

```{r}
# plot the predicted response fields to these variables

visreg2d(PLS.gam14, xvar='MAP1910', yvar='pasttmean', scale='response')
visreg2d(PLS.gam14, xvar='MAP1910', yvar='pastdeltaP', scale='response')
visreg2d(PLS.gam14, xvar='MAP1910', yvar='pastdeltaT', scale='response')

map.pred.density <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
plot(testdata$MAP1910, ypred, pch = 16, xlab = "MAP", ylab = "Predicted")

plot(testdata$pasttmean, ypred, pch = 16, xlab = "pasttmean", ylab = "Predicted")

testdata$ypred <- ypred
ggplot(testdata, aes(x = x, y = y, color = ypred))+geom_point() + theme_bw() +ggtitle ('Predicted tree denisty') 
#outdata <- testdata
}

get.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")

testdata$ypred <- ypred

testdata
}

map.preds(PLS.gam14, test)

```


The above models are predicting density (continious variable) from continous envrionmental and climate covariates. However, we can also use the savanna/forest density classificaitons as our y variable and  predict the probability a grid cell is forest (ecocode = 1, PLS density > 47 trees/ha) and savannna(ecocode = 0, PLSdensity < 47 trees/ha & >0.5 trees/ha) from continous environmental and climate covariates. We develop these models below

```{r echo = FALSE}
#test logistic regressoin
# dummyvariables for logistic regression:
dens.pr$ecocode <- 0
dens.pr[dens.pr$ecotype %in% 'Forest', ]$ecocode <- 1
dens.pr<- dens.pr[!dens.pr$ecotype %in% 'prairie',]
#split training and testing
Y <- dens.pr$PLSdensity
msk <- sample.split( Y, SplitRatio = 1/2, group = NULL )
#table(Y,msk)

train <- dens.pr[msk,]
test <- dens.pr[!msk,]


plot(dens.pr$sandpct, dens.pr$ecotype)


# logmod 
logmod<- gam(ecocode ~ s(MAP1910) , family = binomial, data = train)

logmodL <- gam(ecocode ~ MAP1910 , family = binomial, data = train)
summary(logmod)
plot(logmod)




logmod2<- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(sandpct), family = binomial, data = train)

logmod2L<- gam(ecocode ~ MAP1910 + pasttmean + sandpct, family = binomial, data = train)

summary(logmod2)
summary(logmod2L)
#plot(logmod2)

logmod3 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(pastdeltaP)+ s(sandpct), family = binomial, data = train)

logmod3L <- gam(ecocode ~ MAP1910 + pasttmean + pastdeltaP+ sandpct, family = binomial, data = train)

summary(logmod3L)
summary(logmod3)
#plot(logmod3)

ypred3 <- predict(logmod3, newdata = test, type="response")
plot(test$MAP1910, ypred3, pch = 16, xlab = "MAP", ylab = "Predicted")

logmod4 <- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(pastdeltaP)+ s(pastdeltaT) + s(sandpct), family = binomial, data = train)

logmod4L <- gam(ecocode ~ MAP1910 + pasttmean + pastdeltaP+ pastdeltaT + sandpct, family = binomial, data = train)

summary(logmod4)
#plot(logmod4)

ypred4 <- predict(logmod4, newdata = test, type="response")
plot(test$MAP1910, ypred4, pch = 16, xlab = "MAP", ylab = "Predicted")

logmod5<- gam(ecocode ~ s(MAP1910) + s(pasttmean) + s(pastdeltaP)+ s(pastdeltaT) + s(sandpct) + s(awc), family = binomial, data = train)

logmod5L <- gam(ecocode ~ MAP1910 + pasttmean + pastdeltaP+ pastdeltaT + sandpct + awc, family = binomial, data = train)

summary(logmod5)
plot(logmod5)

ypred5 <- predict(logmod5, newdata = test, type="response")
plot(test$MAP1910, ypred5, pch = 16, xlab = "MAP", ylab = "Predicted")

#plot predicted probabiliy of forest vs. observed tree density
plot(test$PLSdensity, ypred5, pch = 16, xlab = "obs", ylab = "Predicted")

AIC(logmod, logmod2, logmod3, logmod4, logmod5, 
    logmodL, logmod2L, logmod3L, logmod4L, logmod5L)


```

## Results from Generalized additive models of PLS density with covariates:

```{r, echo = FALSE, results = 'asis'}

stargazer(PLS.gam1,PLS.gam2, PLS.gam3, PLS.gam4, PLS.gam5, PLS.gam6, PLS.gam7, PLS.gam8, type="html",
          title            = "GAM model results",dep.var.labels.include = FALSE,
   #       covariate.labels = c("Mean Annual Precipitation (mm)", "Mean Temperature (DegF)", "Mean Temperature (DegF)", "AWC", "Precipitaiton seasonality","% sand"),
          dep.var.caption  = "Pre-settlement tree density",
          dep.var.labels   = "Tree density (trees/ha)")


```

lets map out the probability of forest based on model with the lowest AIC value:
```{r}

library(visreg)
map.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")
plot(testdata$MAP1910, ypred, pch = 16, xlab = "MAP", ylab = "Predicted")

plot(testdata$pasttmean, ypred, pch = 16, xlab = "pasttmean", ylab = "Predicted")

testdata$ypred <- ypred
ggplot(testdata, aes(x = x, y = y, color = ypred))+geom_point() + theme_bw() +ggtitle ('Probability of forest') 
#outdata <- testdata
}

get.preds <- function(model, testdata){
ypred <- predict(model, newdata = testdata, type="response")

testdata$ypred <- ypred

testdata
}

map.preds(logmod5, test)
map.preds(logmod5L, test)
map.preds(logmod4L, test)
map.preds(logmod3L, test)
map.preds(logmod2L, test)

preds.df <- get.preds(logmod5, test)
hist(preds.df$ypred, breaks = 25)
summary(preds.df$ypred)

# plot the predicted response to these variables

visreg2d(logmod5, xvar='MAP1910', yvar='pasttmean', scale='response')
visreg2d(logmod5, xvar='MAP1910', yvar='pastdeltaP', scale='response')
visreg2d(logmod5, xvar='MAP1910', yvar='pastdeltaT', scale='response')
visreg2d(logmod5, xvar='MAP1910', yvar='sandpct', scale='response')
visreg2d(logmod5, xvar='MAP1910', yvar='awc', scale='response')


preds.df <- preds.df[preds.df$ypred < 0.55,]
preds.df<- preds.df[preds.df$ypred > 0.45,]

ggplot(preds.df, aes(x, y)) + geom_point() + theme_bw()
ggplot(preds.df, aes(ecocode,ypred))

```


Estimating the Mixture model
```{r, echo = FALSE}
#library(bayesmix)

#data(faithful)
#hist(train$PLSdensity, breaks = 25)


# we want a mixture model with two components 
#bayesmod <- BMMmodel(train$PLSdensity, k=2, priors=list(kind = "independence", parameter = "priorsUncertain", hierarchical = NULL)) # k=2 for two components

#assign controls for Jags
#jcontrol <- JAGScontrol(variables = c("mu", "tau", "eta", "S"), burn.in = 1000, n.iter = 10000, seed = 10)

#run
#z <- JAGSrun(train$PLSdensity, model = bayesmod, control = jcontrol, tmp = FALSE, cleanup = TRUE)

#zSort <- Sort(z, by = "mu")

#plot mcmc and estimates of mu
#plot(z, variables = "mu")

#zSort

#plot posterior estimates
#BMMposteriori(zSort)

# this estimates 2 modes with a mean of 11.0 and 191.5
# this 


################
#test mixture regression
#library(mixtools)
#data('CO2data')
#attach(CO2data)
#CO2reg <- regmixEM(CO2, GNP, lambda = c(1, 3) / 4,
 #beta = matrix(c(8, -1, 1, 1), 2, 2), sigma = c(2, 1))

#summary(CO2reg)
#plot(CO2reg, density = TRUE, alpha = 0.01)

#try for training datasets
#CO2reg <- regmixEM(train$PLSdensity, train$pasttmean
 #                  , lambda = c(1, 3) / 4,
 #beta = matrix(c(10, -10, 15, 1), 2, 2), sigma = c(2, 1))

#summary(CO2reg)
#plot(CO2reg, density = TRUE, alpha = 0.01)

```
